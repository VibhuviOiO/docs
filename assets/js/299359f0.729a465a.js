"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8096],{2047:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>t,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"Build-ML-Tools/dvc","title":"DVC (Data Version Control)","description":"DVC is an open-source data versioning and ML pipeline tool for managing datasets, experiments, and reproducible ML workflows.","source":"@site/docs/Build-ML-Tools/dvc.md","sourceDirName":"Build-ML-Tools","slug":"/BuildMLTools/DVC","permalink":"/docs/BuildMLTools/DVC","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Build-ML-Tools/dvc.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"DVC (Data Version Control)","description":"DVC is an open-source data versioning and ML pipeline tool for managing datasets, experiments, and reproducible ML workflows.","slug":"/BuildMLTools/DVC","keywords":["DVC","data version control","ML pipelines","data versioning","experiment tracking","reproducible ML","MLOps","data management"]},"sidebar":"tutorialSidebar","previous":{"title":"TensorFlow","permalink":"/docs/BuildMLTools/TensorFlow"},"next":{"title":"MLflow","permalink":"/docs/BuildMLTools/MLflow"}}');var i=r(4848),a=r(8453);const t={sidebar_position:4,title:"DVC (Data Version Control)",description:"DVC is an open-source data versioning and ML pipeline tool for managing datasets, experiments, and reproducible ML workflows.",slug:"/BuildMLTools/DVC",keywords:["DVC","data version control","ML pipelines","data versioning","experiment tracking","reproducible ML","MLOps","data management"]},o="\ud83d\ude80 Data Versioning and ML Pipelines with DVC",l={},d=[{value:"Key Features",id:"key-features",level:2},{value:"Use Cases",id:"use-cases",level:2},{value:"\ud83e\uddf0 Prerequisites",id:"-prerequisites",level:2},{value:"\ud83d\udd27 Step 1: Install and Initialize DVC",id:"-step-1-install-and-initialize-dvc",level:2},{value:"\ud83c\udfd7\ufe0f Step 2: Configure Remote Storage",id:"\ufe0f-step-2-configure-remote-storage",level:2},{value:"\ud83d\udcc1 Step 3: Add Data to DVC Tracking",id:"-step-3-add-data-to-dvc-tracking",level:2},{value:"\u25b6\ufe0f Step 4: Create DVC Pipeline",id:"\ufe0f-step-4-create-dvc-pipeline",level:2},{value:"\ud83d\udcca Step 5: Run and Manage Pipelines",id:"-step-5-run-and-manage-pipelines",level:2},{value:"\ud83d\udd0d What You&#39;ll See",id:"-what-youll-see",level:2},{value:"DVC Pipeline Execution",id:"dvc-pipeline-execution",level:3},{value:"Metrics Comparison",id:"metrics-comparison",level:3},{value:"Experiment Tracking",id:"experiment-tracking",level:3},{value:"Pros &amp; Cons",id:"pros--cons",level:2},{value:"\u2705 Pros",id:"-pros",level:3},{value:"\u274c Cons",id:"-cons",level:3},{value:"Conclusion",id:"conclusion",level:2}];function c(e){const n={br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"-data-versioning-and-ml-pipelines-with-dvc",children:"\ud83d\ude80 Data Versioning and ML Pipelines with DVC"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"DVC (Data Version Control)"})," is an ",(0,i.jsx)(n.strong,{children:"open-source"})," tool for ",(0,i.jsx)(n.strong,{children:"data versioning"}),", ",(0,i.jsx)(n.strong,{children:"ML pipeline management"}),", and ",(0,i.jsx)(n.strong,{children:"experiment tracking"}),". Perfect for ",(0,i.jsx)(n.strong,{children:"reproducible ML workflows"})," with ",(0,i.jsx)(n.strong,{children:"Git-like"})," versioning for datasets and ",(0,i.jsx)(n.strong,{children:"automated pipeline"})," execution."]}),"\n",(0,i.jsx)(n.h2,{id:"key-features",children:"Key Features"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Data Versioning"}),": Git-like versioning for large datasets and models"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Pipeline Management"}),": Define and run reproducible ML pipelines"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Experiment Tracking"}),": Compare experiments and track metrics"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Remote Storage"}),": Support for S3, GCS, Azure, SSH, and more"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Git Integration"}),": Works seamlessly with Git workflows"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Dataset Management"}),": Version control for large datasets"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ML Pipelines"}),": Reproducible training and evaluation workflows"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Experiment Tracking"}),": Compare model performance across experiments"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Team Collaboration"}),": Share data and models across team members"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"-prerequisites",children:"\ud83e\uddf0 Prerequisites"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Git"})," repository initialized"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Python 3.8+"})," installed"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cloud storage"})," (AWS S3, Google Cloud, Azure) or local storage"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ML project"})," with datasets and models"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"-step-1-install-and-initialize-dvc",children:"\ud83d\udd27 Step 1: Install and Initialize DVC"}),"\n",(0,i.jsx)(n.p,{children:"Install DVC with cloud storage support:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Install DVC with cloud storage support\npip install dvc[all]\n\n# Or install with specific cloud provider\npip install dvc[s3]      # AWS S3\npip install dvc[gs]      # Google Cloud Storage\npip install dvc[azure]   # Azure Blob Storage\n\n# Verify installation\ndvc version\n"})}),"\n",(0,i.jsx)(n.p,{children:"Initialize DVC in your Git repository:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Initialize Git repository (if not already done)\ngit init\n\n# Initialize DVC\ndvc init\n\n# Commit DVC initialization\ngit add .dvc/\ngit commit -m "Initialize DVC"\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"\ufe0f-step-2-configure-remote-storage",children:"\ud83c\udfd7\ufe0f Step 2: Configure Remote Storage"}),"\n",(0,i.jsx)(n.p,{children:"Set up remote storage for your data:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Add S3 remote storage\ndvc remote add -d myremote s3://my-dvc-bucket/dvc-storage\n\n# Configure AWS credentials (optional if using AWS CLI)\ndvc remote modify myremote access_key_id YOUR_ACCESS_KEY\ndvc remote modify myremote secret_access_key YOUR_SECRET_KEY\n\n# Commit remote configuration\ngit add .dvc/config\ngit commit -m "Configure DVC remote storage"\n'})}),"\n",(0,i.jsx)(n.p,{children:"For local testing, you can use a local directory:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Add local remote storage\ndvc remote add -d myremote /tmp/dvc-storage\nmkdir -p /tmp/dvc-storage\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"-step-3-add-data-to-dvc-tracking",children:"\ud83d\udcc1 Step 3: Add Data to DVC Tracking"}),"\n",(0,i.jsx)(n.p,{children:"Create a sample project structure and add data:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Create project structure\nmkdir -p data/raw data/processed models\n\n# Add dataset to DVC tracking\ndvc add data/raw/dataset.csv\n\n# Add DVC file to Git (not the actual data)\ngit add data/raw/dataset.csv.dvc data/raw/.gitignore\ngit commit -m "Add raw dataset to DVC"\n\n# Push data to remote storage\ndvc push\n'})}),"\n",(0,i.jsx)(n.p,{children:"Create a parameters file for your ML pipeline:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# params.yaml\nprepare:\n  target_col: "target"\n  test_size: 0.2\n  random_state: 42\n\ntrain:\n  model_type: "random_forest"\n  n_estimators: 100\n  max_depth: 10\n  random_state: 42\n\nevaluate:\n  metrics_file: "metrics.json"\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"\ufe0f-step-4-create-dvc-pipeline",children:"\u25b6\ufe0f Step 4: Create DVC Pipeline"}),"\n",(0,i.jsxs)(n.p,{children:["Define your ML pipeline stages in ",(0,i.jsx)(n.code,{children:"dvc.yaml"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"stages:\n  prepare_data:\n    cmd: python src/prepare_data.py\n    deps:\n      - src/prepare_data.py\n      - data/raw/dataset.csv\n      - params.yaml\n    outs:\n      - data/processed/train.csv\n      - data/processed/test.csv\n\n  train_model:\n    cmd: python src/train_model.py\n    deps:\n      - src/train_model.py\n      - data/processed/train.csv\n      - params.yaml\n    outs:\n      - models/model.pkl\n    metrics:\n      - metrics/train_metrics.json\n\n  evaluate_model:\n    cmd: python src/evaluate_model.py\n    deps:\n      - src/evaluate_model.py\n      - models/model.pkl\n      - data/processed/test.csv\n      - params.yaml\n    metrics:\n      - metrics/eval_metrics.json\n    plots:\n      - plots/confusion_matrix.png\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Create the training script ",(0,i.jsx)(n.code,{children:"src/train_model.py"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nimport yaml\nimport json\nimport joblib\nimport os\n\ndef load_params():\n    with open('params.yaml', 'r') as f:\n        params = yaml.safe_load(f)\n    return params\n\ndef train_model():\n    params = load_params()\n    \n    # Load training data\n    train_data = pd.read_csv('data/processed/train.csv')\n    \n    target_col = params['prepare']['target_col']\n    feature_cols = [col for col in train_data.columns if col != target_col]\n    \n    X_train = train_data[feature_cols]\n    y_train = train_data[target_col]\n    \n    # Initialize model\n    model = RandomForestClassifier(\n        n_estimators=params['train']['n_estimators'],\n        max_depth=params['train']['max_depth'],\n        random_state=params['train']['random_state']\n    )\n    \n    # Train model\n    model.fit(X_train, y_train)\n    \n    # Calculate training metrics\n    y_train_pred = model.predict(X_train)\n    train_accuracy = accuracy_score(y_train, y_train_pred)\n    \n    # Save model\n    os.makedirs('models', exist_ok=True)\n    joblib.dump(model, 'models/model.pkl')\n    \n    # Save training metrics\n    os.makedirs('metrics', exist_ok=True)\n    train_metrics = {\n        'train_accuracy': train_accuracy,\n        'model_type': params['train']['model_type'],\n        'n_features': len(feature_cols),\n        'n_samples': len(X_train)\n    }\n    \n    with open('metrics/train_metrics.json', 'w') as f:\n        json.dump(train_metrics, f, indent=2)\n    \n    print(f\"Model trained successfully! Training accuracy: {train_accuracy:.4f}\")\n\nif __name__ == \"__main__\":\n    train_model()\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"-step-5-run-and-manage-pipelines",children:"\ud83d\udcca Step 5: Run and Manage Pipelines"}),"\n",(0,i.jsx)(n.p,{children:"Execute the DVC pipeline:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Run the entire pipeline\ndvc repro\n\n# Run specific stage\ndvc repro train_model\n\n# Check pipeline status\ndvc status\n\n# Show pipeline DAG\ndvc dag\n"})}),"\n",(0,i.jsx)(n.p,{children:"View metrics and compare experiments:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Show metrics\ndvc metrics show\n\n# Compare metrics across experiments\ndvc metrics diff\n\n# Show plots\ndvc plots show\n\n# Compare plots\ndvc plots diff\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"-what-youll-see",children:"\ud83d\udd0d What You'll See"}),"\n",(0,i.jsx)(n.h3,{id:"dvc-pipeline-execution",children:"DVC Pipeline Execution"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"$ dvc repro\nRunning stage 'prepare_data':\n> python src/prepare_data.py\nData preparation completed!\n\nRunning stage 'train_model':\n> python src/train_model.py\nModel trained successfully! Training accuracy: 0.8542\n\nRunning stage 'evaluate_model':\n> python src/evaluate_model.py\nModel evaluation completed!\n"})}),"\n",(0,i.jsx)(n.h3,{id:"metrics-comparison",children:"Metrics Comparison"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"$ dvc metrics show\nPath                    Value\nmetrics/eval_metrics.json:\n  accuracy              0.8234\n  precision             0.8156\n  recall                0.8234\n  f1_score              0.8187\n"})}),"\n",(0,i.jsx)(n.h3,{id:"experiment-tracking",children:"Experiment Tracking"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Pipeline DAG"}),": Visual representation of your ML pipeline"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Metrics History"}),": Track performance across experiments"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Data Lineage"}),": See how data flows through your pipeline"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Reproducibility"}),": Recreate any experiment exactly"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"pros--cons",children:"Pros & Cons"}),"\n",(0,i.jsx)(n.h3,{id:"-pros",children:"\u2705 Pros"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Git Integration"}),": Works seamlessly with existing Git workflows"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Reproducibility"}),": Ensures experiments can be reproduced exactly"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Storage Agnostic"}),": Supports multiple cloud and local storage options"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Pipeline Management"}),": Automates complex ML workflows"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Lightweight"}),": Minimal overhead compared to full MLOps platforms"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"-cons",children:"\u274c Cons"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Learning Curve"}),": Requires understanding of both Git and DVC concepts"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Command Line"}),": Primarily CLI-based, limited GUI options"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Storage Costs"}),": Large datasets require cloud storage"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Complexity"}),": Can be overkill for simple projects"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,i.jsxs)(n.p,{children:["DVC is perfect for teams that want ",(0,i.jsx)(n.strong,{children:"Git-like versioning"})," for data and ",(0,i.jsx)(n.strong,{children:"reproducible ML pipelines"}),". Choose DVC when you need:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Data versioning"})," for large datasets"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Reproducible ML workflows"})," across team members"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Experiment tracking"})," without vendor lock-in"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Integration"})," with existing Git workflows"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"DVC bridges the gap between traditional software development practices and machine learning workflows, making it easier to collaborate on ML projects."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"What You've Achieved:"}),"\n\u2705 Set up data versioning with DVC",(0,i.jsx)(n.br,{}),"\n","\u2705 Created reproducible ML pipelines",(0,i.jsx)(n.br,{}),"\n","\u2705 Configured remote storage for datasets",(0,i.jsx)(n.br,{}),"\n","\u2705 Implemented experiment tracking",(0,i.jsx)(n.br,{}),"\n","\u2705 Established collaborative ML workflows"]})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>t,x:()=>o});var s=r(6540);const i={},a=s.createContext(i);function t(e){const n=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);