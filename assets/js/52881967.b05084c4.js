"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6313],{2937:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>i,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"Infrastructure/nomad","title":"\ud83d\ude80 HashiCorp Nomad - Simple and Flexible Workload Orchestrator","description":"HashiCorp Nomad is a simple and flexible workload orchestrator that enables organizations to easily deploy, manage, and scale applications across on-premises and cloud environments. It supports containerized, non-containerized, microservice, and batch applications.","source":"@site/docs/Infrastructure/nomad.md","sourceDirName":"Infrastructure","slug":"/Infrastructure/nomad","permalink":"/docs/Infrastructure/nomad","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Infrastructure/nomad.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Bash Scripting","permalink":"/docs/Infrastructure/Bash"},"next":{"title":"K8s Cluster","permalink":"/docs/category/k8s-cluster"}}');var t=a(4848),r=a(8453);const i={},s="\ud83d\ude80 HashiCorp Nomad - Simple and Flexible Workload Orchestrator",l={},c=[{value:"\ud83d\udccb Prerequisites",id:"-prerequisites",level:2},{value:"\ud83d\udee0\ufe0f Installation",id:"\ufe0f-installation",level:2},{value:"Binary Installation",id:"binary-installation",level:3},{value:"Package Manager Installation",id:"package-manager-installation",level:3},{value:"Docker Installation",id:"docker-installation",level:3},{value:"\ud83c\udfd7\ufe0f Basic Configuration",id:"\ufe0f-basic-configuration",level:2},{value:"Server Configuration",id:"server-configuration",level:3},{value:"Client Configuration",id:"client-configuration",level:3},{value:"\ud83d\ude80 Quick Start",id:"-quick-start",level:2},{value:"Start Development Mode",id:"start-development-mode",level:3},{value:"Production Cluster Setup",id:"production-cluster-setup",level:3},{value:"\ud83d\udce6 Job Definitions",id:"-job-definitions",level:2},{value:"Simple Web Application",id:"simple-web-application",level:3},{value:"Batch Processing Job",id:"batch-processing-job",level:3},{value:"Multi-Task Group",id:"multi-task-group",level:3},{value:"\ud83d\udd27 Advanced Features",id:"-advanced-features",level:2},{value:"Volume Management",id:"volume-management",level:3},{value:"Constraints and Affinity",id:"constraints-and-affinity",level:3},{value:"Parameterized Jobs",id:"parameterized-jobs",level:3},{value:"\ud83d\udc33 Docker Compose Integration",id:"-docker-compose-integration",level:2},{value:"Nomad with Consul and Vault",id:"nomad-with-consul-and-vault",level:3},{value:"\ud83d\udcca Monitoring &amp; Observability",id:"-monitoring--observability",level:2},{value:"Prometheus Integration",id:"prometheus-integration",level:3},{value:"Logging Configuration",id:"logging-configuration",level:3},{value:"\ud83d\udd12 Security Configuration",id:"-security-configuration",level:2},{value:"ACL Setup",id:"acl-setup",level:3},{value:"TLS Configuration",id:"tls-configuration",level:3},{value:"Vault Integration",id:"vault-integration",level:3},{value:"\ud83d\ude80 Production Deployment",id:"-production-deployment",level:2},{value:"Systemd Service",id:"systemd-service",level:3},{value:"High Availability Setup",id:"high-availability-setup",level:3},{value:"\ud83d\udd0d Troubleshooting",id:"-troubleshooting",level:2},{value:"Common Commands",id:"common-commands",level:3},{value:"Log Analysis",id:"log-analysis",level:3},{value:"\ud83d\udcc8 Performance Tuning",id:"-performance-tuning",level:2},{value:"Resource Optimization",id:"resource-optimization",level:3},{value:"Scaling Strategies",id:"scaling-strategies",level:3},{value:"\ud83d\udcda Additional Resources",id:"-additional-resources",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"-hashicorp-nomad---simple-and-flexible-workload-orchestrator",children:"\ud83d\ude80 HashiCorp Nomad - Simple and Flexible Workload Orchestrator"})}),"\n",(0,t.jsx)(e.p,{children:"HashiCorp Nomad is a simple and flexible workload orchestrator that enables organizations to easily deploy, manage, and scale applications across on-premises and cloud environments. It supports containerized, non-containerized, microservice, and batch applications."}),"\n",(0,t.jsx)(e.h2,{id:"-prerequisites",children:"\ud83d\udccb Prerequisites"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Linux, macOS, or Windows"}),"\n",(0,t.jsx)(e.li,{children:"Basic understanding of containerization"}),"\n",(0,t.jsx)(e.li,{children:"Docker installed (for container workloads)"}),"\n",(0,t.jsx)(e.li,{children:"Network connectivity between nodes"}),"\n",(0,t.jsx)(e.li,{children:"Consul (optional, for service discovery)"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"\ufe0f-installation",children:"\ud83d\udee0\ufe0f Installation"}),"\n",(0,t.jsx)(e.h3,{id:"binary-installation",children:"Binary Installation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:'# Download Nomad binary\nNOMAD_VERSION="1.6.2"\nwget https://releases.hashicorp.com/nomad/${NOMAD_VERSION}/nomad_${NOMAD_VERSION}_linux_amd64.zip\n\n# Extract and install\nunzip nomad_${NOMAD_VERSION}_linux_amd64.zip\nsudo mv nomad /usr/local/bin/\nsudo chmod +x /usr/local/bin/nomad\n\n# Verify installation\nnomad version\n'})}),"\n",(0,t.jsx)(e.h3,{id:"package-manager-installation",children:"Package Manager Installation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:'# Ubuntu/Debian\ncurl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add -\nsudo apt-add-repository "deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main"\nsudo apt-get update && sudo apt-get install nomad\n\n# CentOS/RHEL\nsudo yum install -y yum-utils\nsudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo\nsudo yum -y install nomad\n\n# macOS\nbrew tap hashicorp/tap\nbrew install hashicorp/tap/nomad\n'})}),"\n",(0,t.jsx)(e.h3,{id:"docker-installation",children:"Docker Installation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Run Nomad in development mode\ndocker run -d --name nomad-dev \\\n  -p 4646:4646 \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  hashicorp/nomad:latest agent -dev -bind 0.0.0.0 -log-level INFO\n"})}),"\n",(0,t.jsx)(e.h2,{id:"\ufe0f-basic-configuration",children:"\ud83c\udfd7\ufe0f Basic Configuration"}),"\n",(0,t.jsx)(e.h3,{id:"server-configuration",children:"Server Configuration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-hcl",children:'# nomad-server.hcl\ndatacenter = "dc1"\ndata_dir   = "/opt/nomad/data"\nlog_level  = "INFO"\nnode_name  = "nomad-server-1"\n\nbind_addr = "0.0.0.0"\n\nserver {\n  enabled          = true\n  bootstrap_expect = 3\n  \n  # Server join configuration\n  server_join {\n    retry_join = ["10.0.1.10", "10.0.1.11", "10.0.1.12"]\n  }\n}\n\nclient {\n  enabled = false\n}\n\nui_config {\n  enabled = true\n}\n\nconsul {\n  address = "127.0.0.1:8500"\n}\n\nacl = {\n  enabled = true\n}\n\ntls {\n  http = true\n  rpc  = true\n\n  ca_file   = "/opt/nomad/tls/nomad-ca.pem"\n  cert_file = "/opt/nomad/tls/server.pem"\n  key_file  = "/opt/nomad/tls/server-key.pem"\n\n  verify_server_hostname = true\n  verify_https_client    = true\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"client-configuration",children:"Client Configuration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-hcl",children:'# nomad-client.hcl\ndatacenter = "dc1"\ndata_dir   = "/opt/nomad/data"\nlog_level  = "INFO"\nnode_name  = "nomad-client-1"\n\nbind_addr = "0.0.0.0"\n\nserver {\n  enabled = false\n}\n\nclient {\n  enabled = true\n  \n  servers = ["10.0.1.10:4647", "10.0.1.11:4647", "10.0.1.12:4647"]\n  \n  node_class = "compute"\n  \n  meta {\n    "type" = "worker"\n    "zone" = "us-west-2a"\n  }\n  \n  options {\n    "driver.raw_exec.enable"    = "1"\n    "driver.docker.enable"      = "1"\n    "driver.java.enable"        = "1"\n  }\n}\n\nconsul {\n  address = "127.0.0.1:8500"\n}\n\nplugin "docker" {\n  config {\n    allow_privileged = true\n    volumes {\n      enabled = true\n    }\n  }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"-quick-start",children:"\ud83d\ude80 Quick Start"}),"\n",(0,t.jsx)(e.h3,{id:"start-development-mode",children:"Start Development Mode"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Start Nomad in dev mode (single node)\nsudo nomad agent -dev -bind 0.0.0.0 -log-level INFO\n\n# Access Web UI\n# http://localhost:4646\n"})}),"\n",(0,t.jsx)(e.h3,{id:"production-cluster-setup",children:"Production Cluster Setup"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Start server nodes\nsudo nomad agent -config=/etc/nomad.d/server.hcl\n\n# Start client nodes\nsudo nomad agent -config=/etc/nomad.d/client.hcl\n\n# Check cluster status\nnomad server members\nnomad node status\n"})}),"\n",(0,t.jsx)(e.h2,{id:"-job-definitions",children:"\ud83d\udce6 Job Definitions"}),"\n",(0,t.jsx)(e.h3,{id:"simple-web-application",children:"Simple Web Application"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-hcl",children:'# webapp.nomad\njob "webapp" {\n  datacenters = ["dc1"]\n  type        = "service"\n\n  group "web" {\n    count = 3\n\n    network {\n      port "http" {\n        static = 8080\n      }\n    }\n\n    service {\n      name = "webapp"\n      port = "http"\n      \n      tags = [\n        "web",\n        "frontend",\n        "urlprefix-/webapp"\n      ]\n\n      check {\n        type     = "http"\n        path     = "/health"\n        interval = "10s"\n        timeout  = "3s"\n      }\n    }\n\n    task "web" {\n      driver = "docker"\n\n      config {\n        image = "nginx:alpine"\n        ports = ["http"]\n        \n        volumes = [\n          "local:/usr/share/nginx/html"\n        ]\n      }\n\n      template {\n        data = <<EOF\n<!DOCTYPE html>\n<html>\n<head><title>Nomad Web App</title></head>\n<body>\n  <h1>Hello from Nomad!</h1>\n  <p>Node: {{ env "node.unique.name" }}</p>\n  <p>Allocation: {{ env "NOMAD_ALLOC_ID" }}</p>\n</body>\n</html>\nEOF\n        destination = "local/index.html"\n      }\n\n      resources {\n        cpu    = 100\n        memory = 128\n      }\n    }\n  }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"batch-processing-job",children:"Batch Processing Job"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-hcl",children:'# batch-job.nomad\njob "data-processing" {\n  datacenters = ["dc1"]\n  type        = "batch"\n\n  group "processors" {\n    count = 5\n\n    task "process" {\n      driver = "docker"\n\n      config {\n        image = "python:3.9-slim"\n        command = "python"\n        args = ["/local/process.py"]\n      }\n\n      template {\n        data = <<EOF\n#!/usr/bin/env python3\nimport os\nimport time\nimport random\n\ndef process_data():\n    print(f"Processing on {os.environ.get(\'NOMAD_ALLOC_ID\')}")\n    \n    # Simulate data processing\n    processing_time = random.randint(30, 120)\n    time.sleep(processing_time)\n    \n    print(f"Processing completed in {processing_time} seconds")\n\nif __name__ == "__main__":\n    process_data()\nEOF\n        destination = "local/process.py"\n        perms = "755"\n      }\n\n      resources {\n        cpu    = 500\n        memory = 256\n      }\n\n      restart {\n        attempts = 3\n        delay    = "30s"\n        interval = "5m"\n        mode     = "fail"\n      }\n    }\n  }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"multi-task-group",children:"Multi-Task Group"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-hcl",children:'# microservice.nomad\njob "microservice" {\n  datacenters = ["dc1"]\n  type        = "service"\n\n  group "api" {\n    count = 2\n\n    network {\n      port "api" {\n        to = 3000\n      }\n      port "metrics" {\n        to = 9090\n      }\n    }\n\n    service {\n      name = "api"\n      port = "api"\n      \n      tags = ["api", "v1"]\n\n      check {\n        type     = "http"\n        path     = "/health"\n        interval = "10s"\n        timeout  = "3s"\n      }\n    }\n\n    service {\n      name = "api-metrics"\n      port = "metrics"\n      tags = ["metrics"]\n    }\n\n    # Main API task\n    task "api" {\n      driver = "docker"\n\n      config {\n        image = "node:16-alpine"\n        ports = ["api"]\n        command = "node"\n        args = ["/local/server.js"]\n      }\n\n      template {\n        data = <<EOF\nconst express = require(\'express\');\nconst app = express();\n\napp.get(\'/health\', (req, res) => {\n  res.json({ status: \'healthy\', timestamp: new Date().toISOString() });\n});\n\napp.get(\'/api/data\', (req, res) => {\n  res.json({ \n    message: \'Hello from Nomad!\',\n    node: process.env.NOMAD_ALLOC_ID \n  });\n});\n\napp.listen(3000, () => {\n  console.log(\'API server running on port 3000\');\n});\nEOF\n        destination = "local/server.js"\n      }\n\n      resources {\n        cpu    = 200\n        memory = 256\n      }\n    }\n\n    # Sidecar metrics task\n    task "metrics" {\n      driver = "docker"\n\n      config {\n        image = "prom/node-exporter:latest"\n        ports = ["metrics"]\n        args = [\n          "--web.listen-address=:9090",\n          "--path.procfs=/host/proc",\n          "--path.sysfs=/host/sys"\n        ]\n      }\n\n      resources {\n        cpu    = 50\n        memory = 64\n      }\n    }\n  }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"-advanced-features",children:"\ud83d\udd27 Advanced Features"}),"\n",(0,t.jsx)(e.h3,{id:"volume-management",children:"Volume Management"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-hcl",children:'# volume-job.nomad\njob "database" {\n  datacenters = ["dc1"]\n  type        = "service"\n\n  group "db" {\n    count = 1\n\n    volume "db-data" {\n      type      = "host"\n      read_only = false\n      source    = "database"\n    }\n\n    task "postgres" {\n      driver = "docker"\n\n      volume_mount {\n        volume      = "db-data"\n        destination = "/var/lib/postgresql/data"\n        read_only   = false\n      }\n\n      config {\n        image = "postgres:13"\n        ports = ["db"]\n      }\n\n      env {\n        POSTGRES_DB       = "myapp"\n        POSTGRES_USER     = "admin"\n        POSTGRES_PASSWORD = "secretpassword"\n      }\n\n      resources {\n        cpu    = 500\n        memory = 512\n      }\n    }\n  }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"constraints-and-affinity",children:"Constraints and Affinity"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-hcl",children:'job "gpu-workload" {\n  datacenters = ["dc1"]\n  type        = "batch"\n\n  constraint {\n    attribute = "${attr.kernel.name}"\n    value     = "linux"\n  }\n\n  constraint {\n    attribute = "${meta.gpu}"\n    value     = "nvidia"\n  }\n\n  affinity {\n    attribute = "${node.class}"\n    value     = "gpu-compute"\n    weight    = 100\n  }\n\n  group "training" {\n    count = 1\n\n    task "ml-training" {\n      driver = "docker"\n\n      config {\n        image = "tensorflow/tensorflow:latest-gpu"\n        command = "python"\n        args = ["/local/train.py"]\n      }\n\n      resources {\n        cpu    = 2000\n        memory = 4096\n        \n        device "nvidia/gpu" {\n          count = 1\n        }\n      }\n    }\n  }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"parameterized-jobs",children:"Parameterized Jobs"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-hcl",children:'job "parameterized-job" {\n  datacenters = ["dc1"]\n  type        = "batch"\n\n  parameterized {\n    payload       = "required"\n    meta_required = ["input_file", "output_dir"]\n    meta_optional = ["debug_mode"]\n  }\n\n  group "worker" {\n    task "process" {\n      driver = "docker"\n\n      config {\n        image = "alpine:latest"\n        command = "/bin/sh"\n        args = ["/local/process.sh"]\n      }\n\n      template {\n        data = <<EOF\n#!/bin/sh\necho "Processing file: {{ env "NOMAD_META_input_file" }}"\necho "Output directory: {{ env "NOMAD_META_output_dir" }}"\necho "Debug mode: {{ env "NOMAD_META_debug_mode" }}"\n\n# Process the payload\ncat > /tmp/payload.txt << \'PAYLOAD_EOF\'\n{{ with $payload := env "NOMAD_PAYLOAD" }}{{ $payload }}{{ end }}\nPAYLOAD_EOF\n\necho "Payload content:"\ncat /tmp/payload.txt\nEOF\n        destination = "local/process.sh"\n        perms = "755"\n      }\n\n      resources {\n        cpu    = 100\n        memory = 128\n      }\n    }\n  }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"-docker-compose-integration",children:"\ud83d\udc33 Docker Compose Integration"}),"\n",(0,t.jsx)(e.h3,{id:"nomad-with-consul-and-vault",children:"Nomad with Consul and Vault"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:'# docker-compose.yml\nversion: \'3.8\'\n\nservices:\n  consul:\n    image: consul:1.16\n    ports:\n      - "8500:8500"\n    command: >\n      consul agent -dev -ui -client=0.0.0.0\n      -log-level=INFO\n    volumes:\n      - consul-data:/consul/data\n\n  vault:\n    image: vault:1.14\n    ports:\n      - "8200:8200"\n    environment:\n      VAULT_DEV_ROOT_TOKEN_ID: myroot\n      VAULT_DEV_LISTEN_ADDRESS: 0.0.0.0:8200\n    cap_add:\n      - IPC_LOCK\n\n  nomad-server:\n    image: hashicorp/nomad:1.6\n    ports:\n      - "4646:4646"\n      - "4647:4647"\n      - "4648:4648"\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - ./nomad-config:/etc/nomad.d\n      - nomad-data:/opt/nomad/data\n    command: >\n      nomad agent -config=/etc/nomad.d/server.hcl\n    depends_on:\n      - consul\n      - vault\n    environment:\n      NOMAD_LOCAL_CONFIG: |\n        datacenter = "dc1"\n        data_dir = "/opt/nomad/data"\n        log_level = "INFO"\n        \n        server {\n          enabled = true\n          bootstrap_expect = 1\n        }\n        \n        client {\n          enabled = true\n        }\n        \n        ui_config {\n          enabled = true\n        }\n        \n        consul {\n          address = "consul:8500"\n        }\n\nvolumes:\n  consul-data:\n  nomad-data:\n'})}),"\n",(0,t.jsx)(e.h2,{id:"-monitoring--observability",children:"\ud83d\udcca Monitoring & Observability"}),"\n",(0,t.jsx)(e.h3,{id:"prometheus-integration",children:"Prometheus Integration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-hcl",children:'# monitoring.nomad\njob "monitoring" {\n  datacenters = ["dc1"]\n  type        = "service"\n\n  group "prometheus" {\n    count = 1\n\n    network {\n      port "prometheus" {\n        static = 9090\n      }\n    }\n\n    service {\n      name = "prometheus"\n      port = "prometheus"\n      tags = ["monitoring"]\n    }\n\n    task "prometheus" {\n      driver = "docker"\n\n      config {\n        image = "prom/prometheus:latest"\n        ports = ["prometheus"]\n        args = [\n          "--config.file=/local/prometheus.yml",\n          "--storage.tsdb.path=/prometheus",\n          "--web.console.libraries=/etc/prometheus/console_libraries",\n          "--web.console.templates=/etc/prometheus/consoles",\n          "--web.enable-lifecycle"\n        ]\n      }\n\n      template {\n        data = <<EOF\nglobal:\n  scrape_interval: 15s\n\nscrape_configs:\n  - job_name: \'nomad\'\n    static_configs:\n      - targets: [\'{{ env "NOMAD_IP_prometheus" }}:4646\']\n    metrics_path: /v1/metrics\n    params:\n      format: [\'prometheus\']\n\n  - job_name: \'consul\'\n    static_configs:\n      - targets: [\'consul:8500\']\n\n  - job_name: \'node-exporter\'\n    consul_sd_configs:\n      - server: \'consul:8500\'\n        services: [\'node-exporter\']\nEOF\n        destination = "local/prometheus.yml"\n      }\n\n      resources {\n        cpu    = 500\n        memory = 512\n      }\n    }\n  }\n\n  group "grafana" {\n    count = 1\n\n    network {\n      port "grafana" {\n        static = 3000\n      }\n    }\n\n    service {\n      name = "grafana"\n      port = "grafana"\n      tags = ["monitoring", "dashboard"]\n    }\n\n    task "grafana" {\n      driver = "docker"\n\n      config {\n        image = "grafana/grafana:latest"\n        ports = ["grafana"]\n      }\n\n      env {\n        GF_SECURITY_ADMIN_PASSWORD = "admin"\n      }\n\n      resources {\n        cpu    = 200\n        memory = 256\n      }\n    }\n  }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"logging-configuration",children:"Logging Configuration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-hcl",children:'# logging.nomad\njob "logging" {\n  datacenters = ["dc1"]\n  type        = "system"\n\n  group "log-collector" {\n    task "fluentd" {\n      driver = "docker"\n\n      config {\n        image = "fluent/fluentd:v1.14-1"\n        ports = ["fluentd"]\n        \n        volumes = [\n          "/var/log:/var/log:ro",\n          "local/fluent.conf:/fluentd/etc/fluent.conf"\n        ]\n      }\n\n      template {\n        data = <<EOF\n<source>\n  @type tail\n  path /var/log/nomad/*.log\n  pos_file /var/log/fluentd-nomad.log.pos\n  tag nomad.*\n  format json\n</source>\n\n<match nomad.**>\n  @type elasticsearch\n  host elasticsearch.service.consul\n  port 9200\n  index_name nomad-logs\n  type_name _doc\n</match>\nEOF\n        destination = "local/fluent.conf"\n      }\n\n      resources {\n        cpu    = 100\n        memory = 128\n      }\n    }\n  }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"-security-configuration",children:"\ud83d\udd12 Security Configuration"}),"\n",(0,t.jsx)(e.h3,{id:"acl-setup",children:"ACL Setup"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:'# Bootstrap ACL system\nnomad acl bootstrap\n\n# Create management policy\ncat > management-policy.hcl << EOF\nnamespace "*" {\n  policy = "write"\n}\nagent {\n  policy = "write"\n}\noperator {\n  policy = "write"\n}\nquota {\n  policy = "write"\n}\nnode {\n  policy = "write"\n}\nhost_volume "*" {\n  policy = "write"\n}\nEOF\n\n# Create policy\nnomad acl policy apply -description "Management policy" management management-policy.hcl\n\n# Create token\nnomad acl token create -name="management-token" -policy=management\n'})}),"\n",(0,t.jsx)(e.h3,{id:"tls-configuration",children:"TLS Configuration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Generate CA\nnomad tls ca create\n\n# Generate server certificates\nnomad tls cert create -server -region global -dc dc1\n\n# Generate client certificates\nnomad tls cert create -client -region global -dc dc1\n"})}),"\n",(0,t.jsx)(e.h3,{id:"vault-integration",children:"Vault Integration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-hcl",children:'# vault-integration.nomad\njob "vault-example" {\n  datacenters = ["dc1"]\n  type        = "service"\n\n  vault {\n    policies = ["database"]\n    change_mode = "restart"\n  }\n\n  group "app" {\n    task "web" {\n      driver = "docker"\n\n      config {\n        image = "nginx:alpine"\n      }\n\n      template {\n        data = <<EOF\n{{ with secret "database/creds/readonly" }}\nDB_USER="{{ .Data.username }}"\nDB_PASS="{{ .Data.password }}"\n{{ end }}\nEOF\n        destination = "secrets/db.env"\n        env = true\n      }\n\n      resources {\n        cpu    = 100\n        memory = 128\n      }\n    }\n  }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"-production-deployment",children:"\ud83d\ude80 Production Deployment"}),"\n",(0,t.jsx)(e.h3,{id:"systemd-service",children:"Systemd Service"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-ini",children:"# /etc/systemd/system/nomad.service\n[Unit]\nDescription=Nomad\nDocumentation=https://www.nomadproject.io/\nRequires=network-online.target\nAfter=network-online.target\nConditionFileNotEmpty=/etc/nomad.d/nomad.hcl\n\n[Service]\nType=notify\nUser=nomad\nGroup=nomad\nExecStart=/usr/local/bin/nomad agent -config=/etc/nomad.d/nomad.hcl\nExecReload=/bin/kill -HUP $MAINPID\nKillMode=process\nRestart=on-failure\nLimitNOFILE=65536\n\n[Install]\nWantedBy=multi-user.target\n"})}),"\n",(0,t.jsx)(e.h3,{id:"high-availability-setup",children:"High Availability Setup"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-hcl",children:'# ha-server.hcl\ndatacenter = "dc1"\ndata_dir   = "/opt/nomad/data"\nlog_level  = "INFO"\n\nserver {\n  enabled          = true\n  bootstrap_expect = 5\n  \n  server_join {\n    retry_join = [\n      "nomad-1.internal:4648",\n      "nomad-2.internal:4648",\n      "nomad-3.internal:4648",\n      "nomad-4.internal:4648",\n      "nomad-5.internal:4648"\n    ]\n  }\n  \n  # Enable automated backups\n  raft_snapshot {\n    interval   = "5m"\n    threshold  = 8192\n    retain     = 2\n  }\n}\n\nautopilot {\n  cleanup_dead_servers      = true\n  last_contact_threshold    = "200ms"\n  max_trailing_logs         = 250\n  server_stabilization_time = "10s"\n  enable_redundancy_zones   = false\n  disable_upgrade_migration = false\n  enable_custom_upgrades    = false\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"-troubleshooting",children:"\ud83d\udd0d Troubleshooting"}),"\n",(0,t.jsx)(e.h3,{id:"common-commands",children:"Common Commands"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Check cluster status\nnomad server members\nnomad node status\n\n# View job status\nnomad job status webapp\nnomad alloc status <alloc-id>\n\n# Debug allocation\nnomad alloc logs <alloc-id>\nnomad alloc fs <alloc-id>\n\n# Drain node for maintenance\nnomad node drain -enable -yes <node-id>\n\n# Check system events\nnomad system gc\nnomad system reconcile summaries\n"})}),"\n",(0,t.jsx)(e.h3,{id:"log-analysis",children:"Log Analysis"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# View Nomad logs\njournalctl -u nomad -f\n\n# Check specific allocation logs\nnomad alloc logs -f <alloc-id> <task-name>\n\n# Export job specification\nnomad job inspect webapp > webapp-current.json\n"})}),"\n",(0,t.jsx)(e.h2,{id:"-performance-tuning",children:"\ud83d\udcc8 Performance Tuning"}),"\n",(0,t.jsx)(e.h3,{id:"resource-optimization",children:"Resource Optimization"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-hcl",children:'# Optimized client configuration\nclient {\n  enabled = true\n  \n  # Increase concurrent allocations\n  max_kill_timeout = "30s"\n  \n  # Optimize GC\n  gc_interval            = "1m"\n  gc_parallel_destroys   = 2\n  gc_disk_usage_threshold = 80\n  gc_inode_usage_threshold = 70\n  gc_max_allocs = 50\n  \n  # Resource reservations\n  reserved {\n    cpu            = 100\n    memory         = 256\n    disk           = 1024\n    reserved_ports = "22,80,8500-8600"\n  }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"scaling-strategies",children:"Scaling Strategies"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-hcl",children:'job "autoscaling-app" {\n  datacenters = ["dc1"]\n  type        = "service"\n\n  group "web" {\n    count = 3\n\n    scaling {\n      enabled = true\n      min     = 2\n      max     = 10\n\n      policy {\n        cooldown            = "2m"\n        evaluation_interval = "30s"\n\n        check "avg_cpu" {\n          source = "prometheus"\n          query  = "avg_cpu_usage"\n\n          strategy "target-value" {\n            target = 70\n          }\n        }\n      }\n    }\n\n    task "app" {\n      driver = "docker"\n      \n      config {\n        image = "myapp:latest"\n      }\n\n      resources {\n        cpu    = 500\n        memory = 256\n      }\n    }\n  }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"-additional-resources",children:"\ud83d\udcda Additional Resources"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"https://www.nomadproject.io/docs",children:"Nomad Documentation"})}),"\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"https://learn.hashicorp.com/nomad",children:"Nomad Tutorials"})}),"\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"https://www.nomadproject.io/docs/job-specification",children:"Job Specification"})}),"\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"https://www.nomadproject.io/api-docs",children:"Nomad API"})}),"\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"https://github.com/hashicorp/nomad/tree/main/plugins",children:"Community Plugins"})}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"HashiCorp Nomad provides a simple yet powerful orchestration platform that bridges the gap between traditional and modern application deployment patterns, offering flexibility without complexity."})]})}function m(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453:(n,e,a)=>{a.d(e,{R:()=>i,x:()=>s});var o=a(6540);const t={},r=o.createContext(t);function i(n){const e=o.useContext(r);return o.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:i(n.components),o.createElement(r.Provider,{value:e},n.children)}}}]);