"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[1702],{1039:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>i,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"Build-ML-Tools/pytorch","title":"PyTorch","description":"PyTorch is Facebook\'s open-source deep learning framework with dynamic computation graphs and CUDA support for GPU acceleration.","source":"@site/docs/Build-ML-Tools/pytorch.md","sourceDirName":"Build-ML-Tools","slug":"/BuildMLTools/PyTorch","permalink":"/docs/docs/BuildMLTools/PyTorch","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Build-ML-Tools/pytorch.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"PyTorch","description":"PyTorch is Facebook\'s open-source deep learning framework with dynamic computation graphs and CUDA support for GPU acceleration.","slug":"/BuildMLTools/PyTorch","keywords":["PyTorch","machine learning","deep learning","CUDA","GPU acceleration","neural networks","Facebook AI","dynamic graphs"]},"sidebar":"tutorialSidebar","previous":{"title":"Build & ML Tools","permalink":"/docs/docs/category/build--ml-tools"},"next":{"title":"HuggingFace Transformers","permalink":"/docs/docs/BuildMLTools/HuggingFace"}}');var s=r(4848),o=r(8453);const i={sidebar_position:1,title:"PyTorch",description:"PyTorch is Facebook's open-source deep learning framework with dynamic computation graphs and CUDA support for GPU acceleration.",slug:"/BuildMLTools/PyTorch",keywords:["PyTorch","machine learning","deep learning","CUDA","GPU acceleration","neural networks","Facebook AI","dynamic graphs"]},a="\ud83d\udd25 Deep Learning with PyTorch Framework",l={},c=[{value:"Key Features",id:"key-features",level:2},{value:"Use Cases",id:"use-cases",level:2},{value:"\ud83e\uddf0 Prerequisites",id:"-prerequisites",level:2},{value:"\ud83d\udd27 Step 1: Setup PyTorch Development Environment",id:"-step-1-setup-pytorch-development-environment",level:2},{value:"\ud83c\udfd7\ufe0f Step 2: Install PyTorch Locally",id:"\ufe0f-step-2-install-pytorch-locally",level:2},{value:"\ud83d\udcc1 Step 3: Create Your First Neural Network",id:"-step-3-create-your-first-neural-network",level:2},{value:"\u25b6\ufe0f Step 4: Train the Model",id:"\ufe0f-step-4-train-the-model",level:2},{value:"\ud83d\udcca Step 5: Model Evaluation and Visualization",id:"-step-5-model-evaluation-and-visualization",level:2},{value:"\ud83d\udd0d What You&#39;ll See",id:"-what-youll-see",level:2},{value:"Training Output",id:"training-output",level:3},{value:"TensorBoard Visualization",id:"tensorboard-visualization",level:3},{value:"Model Performance",id:"model-performance",level:3},{value:"Pros &amp; Cons",id:"pros--cons",level:2},{value:"\u2705 Pros",id:"-pros",level:3},{value:"\u274c Cons",id:"-cons",level:3},{value:"Conclusion",id:"conclusion",level:2}];function d(n){const e={br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"-deep-learning-with-pytorch-framework",children:"\ud83d\udd25 Deep Learning with PyTorch Framework"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"PyTorch"})," is ",(0,s.jsx)(e.strong,{children:"Facebook's"})," open-source ",(0,s.jsx)(e.strong,{children:"deep learning framework"})," with ",(0,s.jsx)(e.strong,{children:"dynamic computation graphs"})," and ",(0,s.jsx)(e.strong,{children:"CUDA support"}),". Perfect for ",(0,s.jsx)(e.strong,{children:"research"}),", ",(0,s.jsx)(e.strong,{children:"prototyping"}),", and ",(0,s.jsx)(e.strong,{children:"production"})," with ",(0,s.jsx)(e.strong,{children:"intuitive"})," Python-first design and ",(0,s.jsx)(e.strong,{children:"GPU acceleration"}),"."]}),"\n",(0,s.jsx)(e.h2,{id:"key-features",children:"Key Features"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Dynamic Computation Graphs"}),": Build and modify networks on-the-fly"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"CUDA Support"}),": Native GPU acceleration for faster training"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Python-First"}),": Intuitive and Pythonic API design"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"TorchScript"}),": Production deployment with C++ runtime"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Ecosystem"}),": Rich ecosystem with torchvision, torchaudio, torchtext"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Computer Vision"}),": Image classification, object detection, segmentation"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Natural Language Processing"}),": Text classification, language models"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Research"}),": Rapid prototyping and experimentation"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Production"}),": Scalable model deployment with TorchServe"]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"-prerequisites",children:"\ud83e\uddf0 Prerequisites"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Python 3.8+"})," installed"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"NVIDIA GPU"})," (optional, for CUDA acceleration)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Docker & Docker Compose"})," for containerized training"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"8GB+ RAM"})," recommended for model training"]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"-step-1-setup-pytorch-development-environment",children:"\ud83d\udd27 Step 1: Setup PyTorch Development Environment"}),"\n",(0,s.jsx)(e.p,{children:"Create a Docker Compose setup for PyTorch development:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-yaml",children:'version: \'3.8\'\n\nservices:\n  pytorch-dev:\n    image: pytorch/pytorch:2.1.0-cuda11.8-cudnn8-devel\n    container_name: pytorch-dev\n    restart: unless-stopped\n    ports:\n      - "8888:8888"  # Jupyter\n      - "6006:6006"  # TensorBoard\n    environment:\n      - JUPYTER_ENABLE_LAB=yes\n      - JUPYTER_TOKEN=pytorch123\n    volumes:\n      - ./notebooks:/workspace/notebooks\n      - ./data:/workspace/data\n      - ./models:/workspace/models\n      - ./src:/workspace/src\n    working_dir: /workspace\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              count: 1\n              capabilities: [gpu]\n    command: >\n      bash -c "\n        pip install jupyter jupyterlab tensorboard matplotlib seaborn scikit-learn &&\n        jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root\n      "\n\n  # TensorBoard for monitoring\n  tensorboard:\n    image: tensorflow/tensorflow:latest\n    container_name: pytorch-tensorboard\n    restart: unless-stopped\n    ports:\n      - "6007:6006"\n    volumes:\n      - ./logs:/logs\n    command: tensorboard --logdir=/logs --host=0.0.0.0 --port=6006\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"\ufe0f-step-2-install-pytorch-locally",children:"\ud83c\udfd7\ufe0f Step 2: Install PyTorch Locally"}),"\n",(0,s.jsx)(e.p,{children:"Install PyTorch with appropriate CUDA support:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# CPU only version\npip install torch torchvision torchaudio\n\n# CUDA 11.8 version\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n\n# CUDA 12.1 version\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n\n# Verify installation\npython -c \"import torch; print(f'PyTorch version: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')\"\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"-step-3-create-your-first-neural-network",children:"\ud83d\udcc1 Step 3: Create Your First Neural Network"}),"\n",(0,s.jsx)(e.p,{children:"Create a comprehensive image classification example:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torch.utils.tensorboard import SummaryWriter\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Data preprocessing\ntransform_train = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n])\n\n# Load CIFAR-10 dataset\ntrain_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntest_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n\n# Create data loaders\nbatch_size = 128\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n\n# Define CNN model\nclass CIFAR10Net(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CIFAR10Net, self).__init__()\n        \n        # Convolutional layers\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        \n        # Batch normalization\n        self.bn1 = nn.BatchNorm2d(32)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.bn3 = nn.BatchNorm2d(128)\n        \n        # Pooling and dropout\n        self.pool = nn.MaxPool2d(2, 2)\n        self.dropout = nn.Dropout(0.5)\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        \n    def forward(self, x):\n        # Conv block 1\n        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n        \n        # Conv block 2\n        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n        \n        # Conv block 3\n        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n        \n        # Flatten\n        x = x.view(-1, 128 * 4 * 4)\n        \n        # Fully connected layers\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        \n        return x\n\n# Initialize model, loss, and optimizer\nmodel = CIFAR10Net().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n\nprint(f\"Model has {sum(p.numel() for p in model.parameters())} parameters\")\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"\ufe0f-step-4-train-the-model",children:"\u25b6\ufe0f Step 4: Train the Model"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"# Training function\ndef train_model(model, train_loader, test_loader, epochs=20):\n    writer = SummaryWriter('logs/pytorch_training')\n    \n    train_losses = []\n    train_accuracies = []\n    test_accuracies = []\n    \n    for epoch in range(epochs):\n        # Training phase\n        model.train()\n        running_loss = 0.0\n        correct_train = 0\n        total_train = 0\n        \n        for batch_idx, (data, target) in enumerate(train_loader):\n            data, target = data.to(device), target.to(device)\n            \n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            _, predicted = torch.max(output.data, 1)\n            total_train += target.size(0)\n            correct_train += (predicted == target).sum().item()\n            \n            if batch_idx % 100 == 0:\n                print(f'Epoch {epoch+1}/{epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n        \n        # Calculate training metrics\n        epoch_loss = running_loss / len(train_loader)\n        train_accuracy = 100. * correct_train / total_train\n        \n        # Evaluation phase\n        model.eval()\n        correct_test = 0\n        total_test = 0\n        \n        with torch.no_grad():\n            for data, target in test_loader:\n                data, target = data.to(device), target.to(device)\n                output = model(data)\n                _, predicted = torch.max(output.data, 1)\n                total_test += target.size(0)\n                correct_test += (predicted == target).sum().item()\n        \n        test_accuracy = 100. * correct_test / total_test\n        \n        # Log metrics\n        writer.add_scalar('Loss/Train', epoch_loss, epoch)\n        writer.add_scalar('Accuracy/Train', train_accuracy, epoch)\n        writer.add_scalar('Accuracy/Test', test_accuracy, epoch)\n        writer.add_scalar('Learning_Rate', optimizer.param_groups[0]['lr'], epoch)\n        \n        # Store metrics\n        train_losses.append(epoch_loss)\n        train_accuracies.append(train_accuracy)\n        test_accuracies.append(test_accuracy)\n        \n        print(f'Epoch {epoch+1}/{epochs}:')\n        print(f'  Train Loss: {epoch_loss:.4f}, Train Acc: {train_accuracy:.2f}%')\n        print(f'  Test Acc: {test_accuracy:.2f}%')\n        print('-' * 50)\n        \n        scheduler.step()\n    \n    writer.close()\n    \n    # Save model\n    torch.save({\n        'epoch': epochs,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'train_losses': train_losses,\n        'train_accuracies': train_accuracies,\n        'test_accuracies': test_accuracies,\n    }, 'models/cifar10_model.pth')\n    \n    return train_losses, train_accuracies, test_accuracies\n\n# Train the model\nprint(\"Starting training...\")\ntrain_losses, train_accs, test_accs = train_model(model, train_loader, test_loader, epochs=20)\nprint(\"Training completed!\")\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"-step-5-model-evaluation-and-visualization",children:"\ud83d\udcca Step 5: Model Evaluation and Visualization"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"# Evaluation and visualization\ndef evaluate_model(model, test_loader):\n    model.eval()\n    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n                   'dog', 'frog', 'horse', 'ship', 'truck']\n    \n    # Get some test samples\n    dataiter = iter(test_loader)\n    images, labels = next(dataiter)\n    images, labels = images.to(device), labels.to(device)\n    \n    # Make predictions\n    with torch.no_grad():\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n    \n    # Visualize results\n    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n    for i in range(8):\n        ax = axes[i//4, i%4]\n        \n        # Denormalize image\n        img = images[i].cpu()\n        img = img * torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1) + torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n        img = torch.clamp(img, 0, 1)\n        \n        ax.imshow(np.transpose(img, (1, 2, 0)))\n        ax.set_title(f'True: {class_names[labels[i]]}\\nPred: {class_names[predicted[i]]}')\n        ax.axis('off')\n    \n    plt.tight_layout()\n    plt.savefig('models/predictions.png')\n    plt.show()\n\n# Evaluate the model\nevaluate_model(model, test_loader)\n\n# Plot training curves\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(train_losses)\nplt.title('Training Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\n\nplt.subplot(1, 2, 2)\nplt.plot(train_accs, label='Train Accuracy')\nplt.plot(test_accs, label='Test Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.legend()\n\nplt.tight_layout()\nplt.savefig('models/training_curves.png')\nplt.show()\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"-what-youll-see",children:"\ud83d\udd0d What You'll See"}),"\n",(0,s.jsx)(e.h3,{id:"training-output",children:"Training Output"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"$ python train.py\nUsing device: cuda\nModel has 1,250,858 parameters\nStarting training...\n\nEpoch 1/20, Batch 0/391, Loss: 2.3026\nEpoch 1/20, Batch 100/391, Loss: 1.8945\nEpoch 1/20, Batch 200/391, Loss: 1.5234\nEpoch 1/20, Batch 300/391, Loss: 1.2876\n\nEpoch 1/20:\n  Train Loss: 1.8234, Train Acc: 32.45%\n  Test Acc: 35.67%\n--------------------------------------------------\n\nEpoch 20/20:\n  Train Loss: 0.3456, Train Acc: 87.89%\n  Test Acc: 82.34%\n--------------------------------------------------\n\nTraining completed!\nModel saved to models/cifar10_model.pth\n"})}),"\n",(0,s.jsx)(e.h3,{id:"tensorboard-visualization",children:"TensorBoard Visualization"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Loss Curves"}),": Training loss decreasing over epochs"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Accuracy Metrics"}),": Train vs test accuracy comparison"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Learning Rate"}),": Scheduler adjustments"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Model Graph"}),": Network architecture visualization"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"model-performance",children:"Model Performance"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"CIFAR-10 Accuracy"}),": Typically achieves 80-85% test accuracy"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Training Time"}),": ~2-3 minutes per epoch on GPU"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Model Size"}),": ~5MB saved model file"]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"pros--cons",children:"Pros & Cons"}),"\n",(0,s.jsx)(e.h3,{id:"-pros",children:"\u2705 Pros"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Dynamic Graphs"}),": Flexible model building and debugging"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Python Integration"}),": Seamless integration with Python ecosystem"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Research Friendly"}),": Excellent for experimentation and prototyping"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"GPU Support"}),": Efficient CUDA acceleration"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Community"}),": Strong research community and ecosystem"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"-cons",children:"\u274c Cons"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Learning Curve"}),": Requires understanding of deep learning concepts"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Memory Usage"}),": Can be memory-intensive for large models"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Production Deployment"}),": More complex than some alternatives"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Debugging"}),": Dynamic graphs can be harder to optimize"]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,s.jsxs)(e.p,{children:["PyTorch is the ",(0,s.jsx)(e.strong,{children:"preferred choice"})," for ",(0,s.jsx)(e.strong,{children:"deep learning research"})," and ",(0,s.jsx)(e.strong,{children:"rapid prototyping"}),". Choose PyTorch when you need:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Flexible model development"})," with dynamic computation graphs"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Research-oriented"})," deep learning projects"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Custom neural network"})," architectures"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"GPU acceleration"})," for training and inference"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"The combination of intuitive Python API and powerful GPU support makes PyTorch ideal for both beginners learning deep learning and researchers pushing the boundaries of AI."}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"What You've Achieved:"}),"\n\u2705 Set up a complete PyTorch development environment",(0,s.jsx)(e.br,{}),"\n","\u2705 Built and trained a CNN for image classification",(0,s.jsx)(e.br,{}),"\n","\u2705 Implemented data augmentation and regularization",(0,s.jsx)(e.br,{}),"\n","\u2705 Created training monitoring with TensorBoard",(0,s.jsx)(e.br,{}),"\n","\u2705 Developed model evaluation and visualization tools"]})]})}function h(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}},8453:(n,e,r)=>{r.d(e,{R:()=>i,x:()=>a});var t=r(6540);const s={},o=t.createContext(s);function i(n){const e=t.useContext(o);return t.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:i(n.components),t.createElement(o.Provider,{value:e},n.children)}}}]);