"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7537],{7501:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>c,frontMatter:()=>s,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"Build-ML-Tools/mlflow","title":"MLflow","description":"MLflow is an open-source platform for managing the complete machine learning lifecycle, including experiment tracking, model packaging, and deployment.","source":"@site/docs/Build-ML-Tools/mlflow.md","sourceDirName":"Build-ML-Tools","slug":"/BuildMLTools/MLflow","permalink":"/docs/docs/BuildMLTools/MLflow","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Build-ML-Tools/mlflow.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"MLflow","description":"MLflow is an open-source platform for managing the complete machine learning lifecycle, including experiment tracking, model packaging, and deployment.","slug":"/BuildMLTools/MLflow","keywords":["MLflow","ML lifecycle","experiment tracking","model management","ML deployment","model registry","MLOps","machine learning"]},"sidebar":"tutorialSidebar","previous":{"title":"DVC (Data Version Control)","permalink":"/docs/docs/BuildMLTools/DVC"},"next":{"title":"Jupyter Notebook","permalink":"/docs/docs/BuildMLTools/Jupyter"}}');var o=r(4848),i=r(8453);const s={sidebar_position:5,title:"MLflow",description:"MLflow is an open-source platform for managing the complete machine learning lifecycle, including experiment tracking, model packaging, and deployment.",slug:"/BuildMLTools/MLflow",keywords:["MLflow","ML lifecycle","experiment tracking","model management","ML deployment","model registry","MLOps","machine learning"]},l="\ud83d\ude80 ML Lifecycle Management with MLflow",a={},d=[{value:"Key Features",id:"key-features",level:2},{value:"Use Cases",id:"use-cases",level:2},{value:"\ud83e\uddf0 Prerequisites",id:"-prerequisites",level:2},{value:"\ud83d\udd27 Step 1: Setup MLflow Development Environment",id:"-step-1-setup-mlflow-development-environment",level:2},{value:"\ud83c\udfd7\ufe0f Step 2: Install MLflow Locally",id:"\ufe0f-step-2-install-mlflow-locally",level:2},{value:"\ud83d\udcc1 Step 3: Create Your First MLflow Experiment",id:"-step-3-create-your-first-mlflow-experiment",level:2},{value:"\u25b6\ufe0f Step 4: Model Registry and Deployment",id:"\ufe0f-step-4-model-registry-and-deployment",level:2},{value:"\ud83d\udcca Step 5: MLflow Projects and Reproducibility",id:"-step-5-mlflow-projects-and-reproducibility",level:2},{value:"\ud83d\udd0d What You&#39;ll See",id:"-what-youll-see",level:2},{value:"MLflow UI Dashboard",id:"mlflow-ui-dashboard",level:3},{value:"Experiment Tracking Output",id:"experiment-tracking-output",level:3},{value:"Model Registry Operations",id:"model-registry-operations",level:3},{value:"Pros &amp; Cons",id:"pros--cons",level:2},{value:"\u2705 Pros",id:"-pros",level:3},{value:"\u274c Cons",id:"-cons",level:3},{value:"Conclusion",id:"conclusion",level:2}];function m(e){const n={br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"-ml-lifecycle-management-with-mlflow",children:"\ud83d\ude80 ML Lifecycle Management with MLflow"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"MLflow"})," is an ",(0,o.jsx)(n.strong,{children:"open-source"})," platform for managing the ",(0,o.jsx)(n.strong,{children:"complete machine learning lifecycle"}),". Perfect for ",(0,o.jsx)(n.strong,{children:"experiment tracking"}),", ",(0,o.jsx)(n.strong,{children:"model packaging"}),", ",(0,o.jsx)(n.strong,{children:"deployment"}),", and ",(0,o.jsx)(n.strong,{children:"collaboration"})," with support for ",(0,o.jsx)(n.strong,{children:"multiple ML frameworks"})," and ",(0,o.jsx)(n.strong,{children:"cloud platforms"}),"."]}),"\n",(0,o.jsx)(n.h2,{id:"key-features",children:"Key Features"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Experiment Tracking"}),": Log parameters, metrics, and artifacts"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Model Registry"}),": Centralized model store with versioning"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Model Deployment"}),": Deploy models to various platforms"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Project Packaging"}),": Reproducible ML projects"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Multi-framework"}),": Works with any ML library"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Experiment Management"}),": Track and compare ML experiments"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Model Versioning"}),": Manage model lifecycle and versions"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Team Collaboration"}),": Share experiments and models across teams"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Production Deployment"}),": Deploy models to production environments"]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"-prerequisites",children:"\ud83e\uddf0 Prerequisites"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Python 3.8+"})," installed"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Docker & Docker Compose"})," for containerized deployment"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Cloud storage"})," (AWS S3, Azure Blob, GCS) for artifact storage"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Database"})," (PostgreSQL, MySQL) for metadata storage"]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"-step-1-setup-mlflow-development-environment",children:"\ud83d\udd27 Step 1: Setup MLflow Development Environment"}),"\n",(0,o.jsx)(n.p,{children:"Create a Docker Compose setup for MLflow:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:'version: \'3.8\'\n\nservices:\n  # PostgreSQL for MLflow metadata\n  postgres:\n    image: postgres:15\n    container_name: mlflow-postgres\n    restart: unless-stopped\n    environment:\n      - POSTGRES_DB=mlflow\n      - POSTGRES_USER=mlflow\n      - POSTGRES_PASSWORD=mlflow123\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    ports:\n      - "5432:5432"\n\n  # MinIO for artifact storage\n  minio:\n    image: minio/minio:latest\n    container_name: mlflow-minio\n    restart: unless-stopped\n    environment:\n      - MINIO_ROOT_USER=minioadmin\n      - MINIO_ROOT_PASSWORD=minioadmin123\n    volumes:\n      - minio_data:/data\n    ports:\n      - "9000:9000"\n      - "9001:9001"\n    command: server /data --console-address ":9001"\n\n  # MLflow Tracking Server\n  mlflow-server:\n    image: python:3.10-slim\n    container_name: mlflow-server\n    restart: unless-stopped\n    depends_on:\n      - postgres\n      - minio\n    environment:\n      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000\n      - AWS_ACCESS_KEY_ID=minioadmin\n      - AWS_SECRET_ACCESS_KEY=minioadmin123\n    ports:\n      - "5000:5000"\n    volumes:\n      - ./mlflow:/mlflow\n    working_dir: /mlflow\n    command: >\n      bash -c "\n        pip install mlflow[extras] psycopg2-binary boto3 &&\n        mlflow server \n        --backend-store-uri postgresql://mlflow:mlflow123@postgres:5432/mlflow\n        --default-artifact-root s3://mlflow-artifacts/\n        --host 0.0.0.0\n        --port 5000\n      "\n\n  # MLflow Development Environment\n  mlflow-dev:\n    image: python:3.10-slim\n    container_name: mlflow-dev\n    restart: unless-stopped\n    depends_on:\n      - mlflow-server\n    environment:\n      - MLFLOW_TRACKING_URI=http://mlflow-server:5000\n      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000\n      - AWS_ACCESS_KEY_ID=minioadmin\n      - AWS_SECRET_ACCESS_KEY=minioadmin123\n    ports:\n      - "8888:8888"  # Jupyter\n    volumes:\n      - ./notebooks:/workspace/notebooks\n      - ./models:/workspace/models\n      - ./data:/workspace/data\n      - ./experiments:/workspace/experiments\n    working_dir: /workspace\n    command: >\n      bash -c "\n        pip install mlflow[extras] jupyter jupyterlab &&\n        pip install scikit-learn pandas numpy matplotlib seaborn &&\n        pip install xgboost lightgbm tensorflow torch &&\n        jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root --allow-root\n      "\n\nvolumes:\n  postgres_data:\n  minio_data:\n'})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"\ufe0f-step-2-install-mlflow-locally",children:"\ud83c\udfd7\ufe0f Step 2: Install MLflow Locally"}),"\n",(0,o.jsx)(n.p,{children:"Install MLflow with all dependencies:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"# Install MLflow with extras\npip install mlflow[extras]\n\n# Install additional ML libraries\npip install scikit-learn pandas numpy matplotlib seaborn\npip install xgboost lightgbm tensorflow torch\n\n# Install cloud storage dependencies\npip install boto3  # AWS S3\npip install azure-storage-blob  # Azure Blob\npip install google-cloud-storage  # Google Cloud Storage\n\n# Verify installation\nmlflow --version\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"-step-3-create-your-first-mlflow-experiment",children:"\ud83d\udcc1 Step 3: Create Your First MLflow Experiment"}),"\n",(0,o.jsx)(n.p,{children:"Create a comprehensive ML experiment with tracking:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport mlflow.sklearn\nimport mlflow.xgboost\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.datasets import load_wine\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\'ignore\')\n\n# Set MLflow tracking URI\nmlflow.set_tracking_uri("http://localhost:5000")\n\n# Create or set experiment\nexperiment_name = "wine-classification-comparison"\nmlflow.set_experiment(experiment_name)\n\n# Load and prepare data\ndef load_and_prepare_data():\n    """Load and prepare the wine dataset"""\n    wine = load_wine()\n    X, y = wine.data, wine.target\n    feature_names = wine.feature_names\n    \n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42, stratify=y\n    )\n    \n    return X_train, X_test, y_train, y_test, feature_names\n\n# Model evaluation function\ndef evaluate_model(model, X_test, y_test):\n    """Evaluate model and return metrics"""\n    y_pred = model.predict(X_test)\n    \n    metrics = {\n        \'accuracy\': accuracy_score(y_test, y_pred),\n        \'precision\': precision_score(y_test, y_pred, average=\'weighted\'),\n        \'recall\': recall_score(y_test, y_pred, average=\'weighted\'),\n        \'f1_score\': f1_score(y_test, y_pred, average=\'weighted\')\n    }\n    \n    return metrics, y_pred\n\n# Train Random Forest with MLflow tracking\ndef train_random_forest(X_train, X_test, y_train, y_test):\n    """Train Random Forest with hyperparameter tuning"""\n    \n    with mlflow.start_run(run_name="random_forest_tuned"):\n        # Log dataset info\n        mlflow.log_param("dataset", "wine")\n        mlflow.log_param("train_samples", len(X_train))\n        mlflow.log_param("test_samples", len(X_test))\n        mlflow.log_param("features", X_train.shape[1])\n        \n        # Hyperparameter tuning\n        param_grid = {\n            \'n_estimators\': [100, 200, 300],\n            \'max_depth\': [5, 10, 15],\n            \'min_samples_split\': [2, 5, 10]\n        }\n        \n        rf = RandomForestClassifier(random_state=42)\n        grid_search = GridSearchCV(rf, param_grid, cv=5, scoring=\'accuracy\', n_jobs=-1)\n        grid_search.fit(X_train, y_train)\n        \n        # Get best model\n        best_rf = grid_search.best_estimator_\n        \n        # Log hyperparameters\n        for param, value in grid_search.best_params_.items():\n            mlflow.log_param(param, value)\n        \n        # Evaluate model\n        metrics, y_pred = evaluate_model(best_rf, X_test, y_test)\n        \n        # Log metrics\n        for metric_name, metric_value in metrics.items():\n            mlflow.log_metric(metric_name, metric_value)\n        \n        # Log model\n        mlflow.sklearn.log_model(\n            best_rf, \n            "random_forest_model",\n            registered_model_name="wine_classifier_rf"\n        )\n        \n        # Create and log feature importance plot\n        feature_importance = pd.DataFrame({\n            \'feature\': range(len(best_rf.feature_importances_)),\n            \'importance\': best_rf.feature_importances_\n        }).sort_values(\'importance\', ascending=False)\n        \n        plt.figure(figsize=(10, 6))\n        sns.barplot(data=feature_importance.head(10), x=\'importance\', y=\'feature\')\n        plt.title(\'Top 10 Feature Importances - Random Forest\')\n        plt.tight_layout()\n        plt.savefig(\'rf_feature_importance.png\')\n        mlflow.log_artifact(\'rf_feature_importance.png\')\n        plt.close()\n        \n        return best_rf, metrics\n\n# Train XGBoost with MLflow tracking\ndef train_xgboost(X_train, X_test, y_train, y_test):\n    """Train XGBoost with hyperparameter tuning"""\n    \n    with mlflow.start_run(run_name="xgboost_tuned"):\n        # Log dataset info\n        mlflow.log_param("dataset", "wine")\n        mlflow.log_param("train_samples", len(X_train))\n        mlflow.log_param("test_samples", len(X_test))\n        mlflow.log_param("features", X_train.shape[1])\n        \n        # Hyperparameter tuning\n        param_grid = {\n            \'n_estimators\': [100, 200, 300],\n            \'max_depth\': [3, 6, 9],\n            \'learning_rate\': [0.01, 0.1, 0.2],\n            \'subsample\': [0.8, 0.9, 1.0]\n        }\n        \n        xgb_model = xgb.XGBClassifier(random_state=42, eval_metric=\'mlogloss\')\n        grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring=\'accuracy\', n_jobs=-1)\n        grid_search.fit(X_train, y_train)\n        \n        # Get best model\n        best_xgb = grid_search.best_estimator_\n        \n        # Log hyperparameters\n        for param, value in grid_search.best_params_.items():\n            mlflow.log_param(param, value)\n        \n        # Evaluate model\n        metrics, y_pred = evaluate_model(best_xgb, X_test, y_test)\n        \n        # Log metrics\n        for metric_name, metric_value in metrics.items():\n            mlflow.log_metric(metric_name, metric_value)\n        \n        # Log model\n        mlflow.xgboost.log_model(\n            best_xgb, \n            "xgboost_model",\n            registered_model_name="wine_classifier_xgb"\n        )\n        \n        # Create and log feature importance plot\n        feature_importance = pd.DataFrame({\n            \'feature\': range(len(best_xgb.feature_importances_)),\n            \'importance\': best_xgb.feature_importances_\n        }).sort_values(\'importance\', ascending=False)\n        \n        plt.figure(figsize=(10, 6))\n        sns.barplot(data=feature_importance.head(10), x=\'importance\', y=\'feature\')\n        plt.title(\'Top 10 Feature Importances - XGBoost\')\n        plt.tight_layout()\n        plt.savefig(\'xgb_feature_importance.png\')\n        mlflow.log_artifact(\'xgb_feature_importance.png\')\n        plt.close()\n        \n        return best_xgb, metrics\n\n# Main execution\nif __name__ == "__main__":\n    print("\ud83d\ude80 Starting MLflow experiment...")\n    \n    # Load data\n    X_train, X_test, y_train, y_test, feature_names = load_and_prepare_data()\n    print(f"\ud83d\udcca Dataset loaded: {X_train.shape[0]} training samples, {X_test.shape[0]} test samples")\n    \n    # Train models\n    print("\ud83c\udf32 Training Random Forest...")\n    rf_model, rf_metrics = train_random_forest(X_train, X_test, y_train, y_test)\n    \n    print("\ud83d\ude80 Training XGBoost...")\n    xgb_model, xgb_metrics = train_xgboost(X_train, X_test, y_train, y_test)\n    \n    # Compare results\n    print("\\n\ud83d\udcc8 Model Comparison:")\n    print("Random Forest:")\n    for metric, value in rf_metrics.items():\n        print(f"  {metric}: {value:.4f}")\n    \n    print("XGBoost:")\n    for metric, value in xgb_metrics.items():\n        print(f"  {metric}: {value:.4f}")\n    \n    print("\\n\u2705 Experiments completed! Check MLflow UI at http://localhost:5000")\n'})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"\ufe0f-step-4-model-registry-and-deployment",children:"\u25b6\ufe0f Step 4: Model Registry and Deployment"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom mlflow.tracking import MlflowClient\nimport pandas as pd\nimport numpy as np\n\n# Initialize MLflow client\nclient = MlflowClient()\n\n# Model registry operations\ndef manage_model_registry():\n    """Demonstrate model registry operations"""\n    \n    # List registered models\n    registered_models = client.search_registered_models()\n    print("\ud83d\udccb Registered Models:")\n    for model in registered_models:\n        print(f"  - {model.name}")\n    \n    # Get model versions\n    model_name = "wine_classifier_rf"\n    model_versions = client.search_model_versions(f"name=\'{model_name}\'")\n    \n    print(f"\\n\ud83d\udce6 Versions for {model_name}:")\n    for version in model_versions:\n        print(f"  Version {version.version}: {version.current_stage}")\n    \n    # Transition model to staging\n    if model_versions:\n        latest_version = model_versions[0]\n        client.transition_model_version_stage(\n            name=model_name,\n            version=latest_version.version,\n            stage="Staging"\n        )\n        print(f"\u2705 Model version {latest_version.version} transitioned to Staging")\n\n# Model serving function\ndef serve_model_predictions():\n    """Load and serve model predictions"""\n    \n    # Load model from registry\n    model_name = "wine_classifier_rf"\n    stage = "Staging"\n    \n    model_uri = f"models:/{model_name}/{stage}"\n    loaded_model = mlflow.sklearn.load_model(model_uri)\n    \n    # Sample prediction data\n    sample_data = np.array([[\n        13.20, 1.78, 2.14, 11.2, 100, 2.65, 2.76, 0.26, 1.28, 4.38, 1.05, 3.40, 1050\n    ]])\n    \n    # Make prediction\n    prediction = loaded_model.predict(sample_data)\n    prediction_proba = loaded_model.predict_proba(sample_data)\n    \n    print(f"\ud83d\udd2e Prediction: {prediction[0]}")\n    print(f"\ud83d\udcca Prediction Probabilities: {prediction_proba[0]}")\n    \n    return prediction, prediction_proba\n\n# Model deployment with MLflow\ndef deploy_model_locally():\n    """Deploy model as REST API locally"""\n    \n    model_name = "wine_classifier_rf"\n    stage = "Staging"\n    \n    # This would typically be run from command line\n    deployment_command = f"""\n    mlflow models serve \\\\\n        --model-uri models:/{model_name}/{stage} \\\\\n        --host 0.0.0.0 \\\\\n        --port 8080 \\\\\n        --no-conda\n    """\n    \n    print("\ud83d\ude80 To deploy model as REST API, run:")\n    print(deployment_command)\n    \n    # Example curl command for testing\n    curl_command = """\n    curl -X POST http://localhost:8080/invocations \\\\\n        -H \'Content-Type: application/json\' \\\\\n        -d \'{\n            "dataframe_split": {\n                "columns": ["feature_0", "feature_1", "feature_2", "feature_3", "feature_4", "feature_5", "feature_6", "feature_7", "feature_8", "feature_9", "feature_10", "feature_11", "feature_12"],\n                "data": [[13.20, 1.78, 2.14, 11.2, 100, 2.65, 2.76, 0.26, 1.28, 4.38, 1.05, 3.40, 1050]]\n            }\n        }\'\n    """\n    \n    print("\\n\ud83e\uddea Test deployment with:")\n    print(curl_command)\n\nif __name__ == "__main__":\n    print("\ud83d\udd27 Managing model registry...")\n    manage_model_registry()\n    \n    print("\\n\ud83c\udfaf Serving model predictions...")\n    serve_model_predictions()\n    \n    print("\\n\ud83d\ude80 Model deployment instructions...")\n    deploy_model_locally()\n'})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"-step-5-mlflow-projects-and-reproducibility",children:"\ud83d\udcca Step 5: MLflow Projects and Reproducibility"}),"\n",(0,o.jsx)(n.p,{children:"Create an MLproject file for reproducible experiments:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:'# MLproject\nname: wine-classification\n\nconda_env: conda.yaml\n\nentry_points:\n  main:\n    parameters:\n      max_depth: {type: int, default: 10}\n      n_estimators: {type: int, default: 100}\n      test_size: {type: float, default: 0.2}\n    command: "python train.py --max-depth {max_depth} --n-estimators {n_estimators} --test-size {test_size}"\n  \n  evaluate:\n    parameters:\n      model_uri: {type: str}\n    command: "python evaluate.py --model-uri {model_uri}"\n'})}),"\n",(0,o.jsx)(n.p,{children:"Create a conda environment file:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:"# conda.yaml\nname: wine-classification\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.10\n  - pip\n  - pip:\n    - mlflow[extras]\n    - scikit-learn\n    - pandas\n    - numpy\n    - matplotlib\n    - seaborn\n    - xgboost\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"-what-youll-see",children:"\ud83d\udd0d What You'll See"}),"\n",(0,o.jsx)(n.h3,{id:"mlflow-ui-dashboard",children:"MLflow UI Dashboard"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Experiments"}),": List of all experiments with run comparisons"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Models"}),": Registered models with version history"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Artifacts"}),": Stored model files, plots, and data"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Metrics"}),": Interactive charts showing model performance"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"experiment-tracking-output",children:"Experiment Tracking Output"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"\ud83d\ude80 Starting MLflow experiment...\n\ud83d\udcca Dataset loaded: 142 training samples, 36 test samples\n\n\ud83c\udf32 Training Random Forest...\nBest parameters: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}\n\n\ud83d\ude80 Training XGBoost...\nBest parameters: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200, 'subsample': 0.9}\n\n\ud83d\udcc8 Model Comparison:\nRandom Forest:\n  accuracy: 0.9722\n  precision: 0.9733\n  recall: 0.9722\n  f1_score: 0.9722\n\nXGBoost:\n  accuracy: 0.9444\n  precision: 0.9500\n  recall: 0.9444\n  f1_score: 0.9433\n\n\u2705 Experiments completed! Check MLflow UI at http://localhost:5000\n"})}),"\n",(0,o.jsx)(n.h3,{id:"model-registry-operations",children:"Model Registry Operations"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"\ud83d\udd27 Managing model registry...\n\ud83d\udccb Registered Models:\n  - wine_classifier_rf\n  - wine_classifier_xgb\n\n\ud83d\udce6 Versions for wine_classifier_rf:\n  Version 1: None\n  Version 2: Staging\n\n\u2705 Model version 2 transitioned to Staging\n"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"pros--cons",children:"Pros & Cons"}),"\n",(0,o.jsx)(n.h3,{id:"-pros",children:"\u2705 Pros"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Complete ML Lifecycle"}),": Covers experiment tracking to deployment"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Framework Agnostic"}),": Works with any ML library"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Open Source"}),": No vendor lock-in, self-hosted option"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Model Registry"}),": Centralized model management and versioning"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Reproducibility"}),": Ensures experiments can be reproduced"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"-cons",children:"\u274c Cons"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Setup Complexity"}),": Requires infrastructure setup for production"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Storage Costs"}),": Artifacts and models require storage space"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Learning Curve"}),": Requires understanding of MLOps concepts"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"UI Limitations"}),": Web UI has limited customization options"]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,o.jsxs)(n.p,{children:["MLflow is the ",(0,o.jsx)(n.strong,{children:"comprehensive solution"})," for ",(0,o.jsx)(n.strong,{children:"ML lifecycle management"}),". Choose MLflow when you need:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"End-to-end ML workflow"})," management"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Experiment tracking"})," and comparison"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Model versioning"})," and registry"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Reproducible ML projects"})," across teams"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"MLflow bridges the gap between experimentation and production, making it easier to manage the complete machine learning lifecycle."}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"What You've Achieved:"}),"\n\u2705 Set up a complete MLflow environment with tracking server",(0,o.jsx)(n.br,{}),"\n","\u2705 Implemented comprehensive experiment tracking",(0,o.jsx)(n.br,{}),"\n","\u2705 Created model registry with version management",(0,o.jsx)(n.br,{}),"\n","\u2705 Built reproducible ML projects with MLproject files",(0,o.jsx)(n.br,{}),"\n","\u2705 Established model deployment and serving capabilities"]})]})}function c(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(m,{...e})}):m(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>l});var t=r(6540);const o={},i=t.createContext(o);function s(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);