"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6185],{4875:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"Infrastructure/packer","title":"HashiCorp Packer","description":"HashiCorp Packer is a tool for creating identical machine images for multiple platforms from a single source configuration, enabling immutable infrastructure.","source":"@site/docs/Infrastructure/packer.md","sourceDirName":"Infrastructure","slug":"/Infrastructure/Packer","permalink":"/docs/docs/Infrastructure/Packer","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Infrastructure/packer.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7,"title":"HashiCorp Packer","description":"HashiCorp Packer is a tool for creating identical machine images for multiple platforms from a single source configuration, enabling immutable infrastructure.","slug":"/Infrastructure/Packer","keywords":["HashiCorp Packer","machine images","immutable infrastructure","image automation","multi-platform builds","infrastructure as code","AMI","Docker images"]},"sidebar":"tutorialSidebar","previous":{"title":"Ansible","permalink":"/docs/docs/Infrastructure/Ansible"},"next":{"title":"Istio Service Mesh","permalink":"/docs/docs/Infrastructure/Istio"}}');var s=a(4848),r=a(8453);const i={sidebar_position:7,title:"HashiCorp Packer",description:"HashiCorp Packer is a tool for creating identical machine images for multiple platforms from a single source configuration, enabling immutable infrastructure.",slug:"/Infrastructure/Packer",keywords:["HashiCorp Packer","machine images","immutable infrastructure","image automation","multi-platform builds","infrastructure as code","AMI","Docker images"]},o="\ud83d\udce6 Automated Machine Image Creation with HashiCorp Packer",l={},c=[{value:"Key Features",id:"key-features",level:2},{value:"Use Cases",id:"use-cases",level:2},{value:"\ud83e\uddf0 Prerequisites",id:"-prerequisites",level:2},{value:"\ud83d\udd27 Step 1: Packer Installation and Setup",id:"-step-1-packer-installation-and-setup",level:2},{value:"Install Packer",id:"install-packer",level:3},{value:"\ud83c\udfd7\ufe0f Step 2: Basic Packer Templates",id:"\ufe0f-step-2-basic-packer-templates",level:2},{value:"AWS AMI Template (HCL2 Format)",id:"aws-ami-template-hcl2-format",level:3},{value:"\u25b6\ufe0f Step 3: Advanced Provisioning Scripts",id:"\ufe0f-step-3-advanced-provisioning-scripts",level:2},{value:"Docker Installation Script",id:"docker-installation-script",level:3},{value:"Security Hardening with Ansible",id:"security-hardening-with-ansible",level:3},{value:"\ud83d\udcca Step 4: CI/CD Integration",id:"-step-4-cicd-integration",level:2},{value:"GitHub Actions Workflow",id:"github-actions-workflow",level:3},{value:"Multi-Platform Build Results",id:"multi-platform-build-results",level:3},{value:"Pros &amp; Cons",id:"pros--cons",level:2},{value:"\u2705 Pros",id:"-pros",level:3},{value:"\u274c Cons",id:"-cons",level:3},{value:"Conclusion",id:"conclusion",level:2}];function u(n){const e={br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"-automated-machine-image-creation-with-hashicorp-packer",children:"\ud83d\udce6 Automated Machine Image Creation with HashiCorp Packer"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"HashiCorp Packer"})," is a ",(0,s.jsx)(e.strong,{children:"multi-platform"})," tool for creating ",(0,s.jsx)(e.strong,{children:"identical machine images"})," from a ",(0,s.jsx)(e.strong,{children:"single source configuration"}),". Perfect for ",(0,s.jsx)(e.strong,{children:"immutable infrastructure"}),", ",(0,s.jsx)(e.strong,{children:"consistent deployments"}),", and ",(0,s.jsx)(e.strong,{children:"automated image pipelines"})," across ",(0,s.jsx)(e.strong,{children:"cloud providers"})," and ",(0,s.jsx)(e.strong,{children:"virtualization platforms"}),"."]}),"\n",(0,s.jsx)(e.h2,{id:"key-features",children:"Key Features"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Multi-Platform Support"}),": Build images for AWS, Azure, GCP, VMware, Docker, and more"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Immutable Infrastructure"}),": Create consistent, reproducible machine images"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Parallel Builds"}),": Build multiple images simultaneously"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Provisioner Ecosystem"}),": Shell, Ansible, Chef, Puppet integration"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Template-Based"}),": JSON and HCL configuration formats"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Cloud Migration"}),": Create consistent images across cloud providers"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Golden Images"}),": Standardized base images for organizations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"CI/CD Integration"}),": Automated image builds in deployment pipelines"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Security Hardening"}),": Baked-in security configurations and patches"]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"-prerequisites",children:"\ud83e\uddf0 Prerequisites"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"HashiCorp Packer"})," installed locally"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Cloud provider credentials"})," (AWS, Azure, GCP)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Docker"})," for container image builds"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Virtualization software"})," (VirtualBox, VMware) for local builds"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Configuration management tools"})," (Ansible, Chef, Puppet) optional"]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"-step-1-packer-installation-and-setup",children:"\ud83d\udd27 Step 1: Packer Installation and Setup"}),"\n",(0,s.jsx)(e.h3,{id:"install-packer",children:"Install Packer"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:'# Install Packer on Linux/macOS\ncurl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add -\nsudo apt-add-repository "deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main"\nsudo apt-get update && sudo apt-get install packer\n\n# Or using Homebrew on macOS\nbrew install packer\n\n# Verify installation\npacker version\n```### Envir\nonment Setup\n\n```bash\n# Set up AWS credentials\nexport AWS_ACCESS_KEY_ID="your-access-key"\nexport AWS_SECRET_ACCESS_KEY="your-secret-key"\nexport AWS_DEFAULT_REGION="us-west-2"\n\n# Set up Azure credentials\nexport ARM_CLIENT_ID="your-client-id"\nexport ARM_CLIENT_SECRET="your-client-secret"\nexport ARM_SUBSCRIPTION_ID="your-subscription-id"\nexport ARM_TENANT_ID="your-tenant-id"\n\n# Set up GCP credentials\nexport GOOGLE_APPLICATION_CREDENTIALS="/path/to/service-account.json"\nexport GOOGLE_PROJECT="your-project-id"\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"\ufe0f-step-2-basic-packer-templates",children:"\ud83c\udfd7\ufe0f Step 2: Basic Packer Templates"}),"\n",(0,s.jsx)(e.h3,{id:"aws-ami-template-hcl2-format",children:"AWS AMI Template (HCL2 Format)"}),"\n",(0,s.jsxs)(e.p,{children:["Create ",(0,s.jsx)(e.code,{children:"aws-ubuntu.pkr.hcl"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-hcl",children:'packer {\n  required_plugins {\n    amazon = {\n      version = ">= 1.2.8"\n      source  = "github.com/hashicorp/amazon"\n    }\n  }\n}\n\nvariable "region" {\n  type    = string\n  default = "us-west-2"\n}\n\nvariable "instance_type" {\n  type    = string\n  default = "t3.micro"\n}\n\nvariable "ami_name" {\n  type    = string\n  default = "custom-ubuntu-{{timestamp}}"\n}\n\nlocals {\n  timestamp = regex_replace(timestamp(), "[- TZ:]", "")\n}\n\nsource "amazon-ebs" "ubuntu" {\n  ami_name      = var.ami_name\n  instance_type = var.instance_type\n  region        = var.region\n  \n  source_ami_filter {\n    filters = {\n      name                = "ubuntu/images/*ubuntu-jammy-22.04-amd64-server-*"\n      root-device-type    = "ebs"\n      virtualization-type = "hvm"\n    }\n    most_recent = true\n    owners      = ["099720109477"] # Canonical\n  }\n  \n  ssh_username = "ubuntu"\n  \n  tags = {\n    Name        = var.ami_name\n    Environment = "production"\n    OS_Version  = "Ubuntu 22.04"\n    Base_AMI    = "{{ .SourceAMI }}"\n    Built_By    = "Packer"\n  }\n}\n\nbuild {\n  name = "ubuntu-build"\n  sources = [\n    "source.amazon-ebs.ubuntu"\n  ]\n  \n  # Update system packages\n  provisioner "shell" {\n    inline = [\n      "echo \'Updating system packages...\'",\n      "sudo apt-get update",\n      "sudo apt-get upgrade -y",\n      "sudo apt-get install -y curl wget unzip jq"\n    ]\n  }\n  \n  # Install Docker\n  provisioner "shell" {\n    script = "scripts/install-docker.sh"\n  }\n  \n  # Install monitoring agents\n  provisioner "shell" {\n    script = "scripts/install-monitoring.sh"\n  }\n  \n  # Security hardening\n  provisioner "ansible" {\n    playbook_file = "ansible/security-hardening.yml"\n    user          = "ubuntu"\n  }\n  \n  # Clean up\n  provisioner "shell" {\n    inline = [\n      "echo \'Cleaning up...\'",\n      "sudo apt-get autoremove -y",\n      "sudo apt-get autoclean",\n      "sudo rm -rf /tmp/*",\n      "history -c"\n    ]\n  }\n}\n```### Mul\nti-Platform Template\n\nCreate `multi-platform.pkr.hcl`:\n\n```hcl\npacker {\n  required_plugins {\n    amazon = {\n      version = ">= 1.2.8"\n      source  = "github.com/hashicorp/amazon"\n    }\n    azure = {\n      version = ">= 1.4.0"\n      source  = "github.com/hashicorp/azure"\n    }\n    googlecompute = {\n      version = ">= 1.1.1"\n      source  = "github.com/hashicorp/googlecompute"\n    }\n  }\n}\n\nvariable "application_name" {\n  type    = string\n  default = "webapp"\n}\n\nvariable "version" {\n  type    = string\n  default = "1.0.0"\n}\n\nlocals {\n  timestamp = regex_replace(timestamp(), "[- TZ:]", "")\n  image_name = "${var.application_name}-${var.version}-${local.timestamp}"\n}\n\n# AWS Source\nsource "amazon-ebs" "aws" {\n  ami_name      = local.image_name\n  instance_type = "t3.micro"\n  region        = "us-west-2"\n  \n  source_ami_filter {\n    filters = {\n      name                = "ubuntu/images/*ubuntu-jammy-22.04-amd64-server-*"\n      root-device-type    = "ebs"\n      virtualization-type = "hvm"\n    }\n    most_recent = true\n    owners      = ["099720109477"]\n  }\n  \n  ssh_username = "ubuntu"\n  \n  tags = {\n    Name = local.image_name\n    Platform = "AWS"\n  }\n}\n\n# Azure Source\nsource "azure-arm" "azure" {\n  client_id       = var.client_id\n  client_secret   = var.client_secret\n  tenant_id       = var.tenant_id\n  subscription_id = var.subscription_id\n  \n  managed_image_resource_group_name = "packer-images"\n  managed_image_name                = local.image_name\n  \n  os_type         = "Linux"\n  image_publisher = "Canonical"\n  image_offer     = "0001-com-ubuntu-server-jammy"\n  image_sku       = "22_04-lts-gen2"\n  \n  location = "East US"\n  vm_size  = "Standard_B1s"\n}\n\n# GCP Source\nsource "googlecompute" "gcp" {\n  project_id   = var.project_id\n  source_image = "ubuntu-2204-jammy-v20231030"\n  zone         = "us-central1-a"\n  \n  image_name        = local.image_name\n  image_description = "Custom image built with Packer"\n  \n  machine_type = "e2-micro"\n  ssh_username = "ubuntu"\n  \n  image_labels = {\n    environment = "production"\n    built_by    = "packer"\n  }\n}\n\nbuild {\n  sources = [\n    "source.amazon-ebs.aws",\n    "source.azure-arm.azure",\n    "source.googlecompute.gcp"\n  ]\n  \n  # Common provisioning steps\n  provisioner "shell" {\n    inline = [\n      "sudo apt-get update",\n      "sudo apt-get install -y nginx",\n      "sudo systemctl enable nginx"\n    ]\n  }\n  \n  # Application-specific setup\n  provisioner "file" {\n    source      = "app/"\n    destination = "/tmp/app"\n  }\n  \n  provisioner "shell" {\n    script = "scripts/setup-application.sh"\n  }\n}\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"\ufe0f-step-3-advanced-provisioning-scripts",children:"\u25b6\ufe0f Step 3: Advanced Provisioning Scripts"}),"\n",(0,s.jsx)(e.h3,{id:"docker-installation-script",children:"Docker Installation Script"}),"\n",(0,s.jsxs)(e.p,{children:["Create ",(0,s.jsx)(e.code,{children:"scripts/install-docker.sh"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:'#!/bin/bash\nset -e\n\necho "Installing Docker..."\n\n# Update package index\nsudo apt-get update\n\n# Install prerequisites\nsudo apt-get install -y \\\n    ca-certificates \\\n    curl \\\n    gnupg \\\n    lsb-release\n\n# Add Docker\'s official GPG key\nsudo mkdir -m 0755 -p /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n\n# Set up repository\necho \\\n  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n\n# Install Docker Engine\nsudo apt-get update\nsudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n\n# Add ubuntu user to docker group\nsudo usermod -aG docker ubuntu\n\n# Enable and start Docker\nsudo systemctl enable docker\nsudo systemctl start docker\n\n# Install Docker Compose\nsudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose\nsudo chmod +x /usr/local/bin/docker-compose\n\necho "Docker installation completed!"\n```#\n## Monitoring Agent Installation\n\nCreate `scripts/install-monitoring.sh`:\n\n```bash\n#!/bin/bash\nset -e\n\necho "Installing monitoring agents..."\n\n# Install Node Exporter for Prometheus\nNODE_EXPORTER_VERSION="1.6.1"\ncd /tmp\nwget https://github.com/prometheus/node_exporter/releases/download/v${NODE_EXPORTER_VERSION}/node_exporter-${NODE_EXPORTER_VERSION}.linux-amd64.tar.gz\ntar xvfz node_exporter-${NODE_EXPORTER_VERSION}.linux-amd64.tar.gz\nsudo cp node_exporter-${NODE_EXPORTER_VERSION}.linux-amd64/node_exporter /usr/local/bin/\nsudo chown root:root /usr/local/bin/node_exporter\n\n# Create node_exporter user\nsudo useradd --no-create-home --shell /bin/false node_exporter\n\n# Create systemd service\nsudo tee /etc/systemd/system/node_exporter.service > /dev/null <<EOF\n[Unit]\nDescription=Node Exporter\nWants=network-online.target\nAfter=network-online.target\n\n[Service]\nUser=node_exporter\nGroup=node_exporter\nType=simple\nExecStart=/usr/local/bin/node_exporter\n\n[Install]\nWantedBy=multi-user.target\nEOF\n\n# Enable and start node_exporter\nsudo systemctl daemon-reload\nsudo systemctl enable node_exporter\nsudo systemctl start node_exporter\n\n# Install Filebeat for log shipping\ncurl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.11.0-amd64.deb\nsudo dpkg -i filebeat-8.11.0-amd64.deb\n\n# Configure Filebeat\nsudo tee /etc/filebeat/filebeat.yml > /dev/null <<EOF\nfilebeat.inputs:\n- type: log\n  enabled: true\n  paths:\n    - /var/log/*.log\n    - /var/log/syslog\n    - /var/log/auth.log\n\noutput.elasticsearch:\n  hosts: ["elasticsearch:9200"]\n\nprocessors:\n  - add_host_metadata:\n      when.not.contains.tags: forwarded\nEOF\n\nsudo systemctl enable filebeat\n\necho "Monitoring agents installed successfully!"\n'})}),"\n",(0,s.jsx)(e.h3,{id:"security-hardening-with-ansible",children:"Security Hardening with Ansible"}),"\n",(0,s.jsxs)(e.p,{children:["Create ",(0,s.jsx)(e.code,{children:"ansible/security-hardening.yml"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-yaml",children:"---\n- name: Security Hardening\n  hosts: all\n  become: yes\n  vars:\n    allowed_ssh_users:\n      - ubuntu\n      - admin\n    \n  tasks:\n    - name: Update all packages\n      apt:\n        upgrade: dist\n        update_cache: yes\n        cache_valid_time: 3600\n    \n    - name: Install security packages\n      apt:\n        name:\n          - fail2ban\n          - ufw\n          - unattended-upgrades\n          - aide\n          - rkhunter\n          - chkrootkit\n        state: present\n    \n    - name: Configure automatic security updates\n      copy:\n        dest: /etc/apt/apt.conf.d/20auto-upgrades\n        content: |\n          APT::Periodic::Update-Package-Lists \"1\";\n          APT::Periodic::Unattended-Upgrade \"1\";\n    \n    - name: Configure UFW firewall\n      ufw:\n        rule: \"{{ item.rule }}\"\n        port: \"{{ item.port }}\"\n        proto: \"{{ item.proto | default('tcp') }}\"\n      loop:\n        - { rule: 'allow', port: '22' }\n        - { rule: 'allow', port: '80' }\n        - { rule: 'allow', port: '443' }\n        - { rule: 'allow', port: '9100' }  # Node Exporter\n    \n    - name: Enable UFW\n      ufw:\n        state: enabled\n        policy: deny\n        direction: incoming\n    \n    - name: Configure SSH security\n      lineinfile:\n        path: /etc/ssh/sshd_config\n        regexp: \"{{ item.regexp }}\"\n        line: \"{{ item.line }}\"\n        backup: yes\n      loop:\n        - { regexp: '^#?PermitRootLogin', line: 'PermitRootLogin no' }\n        - { regexp: '^#?PasswordAuthentication', line: 'PasswordAuthentication no' }\n        - { regexp: '^#?X11Forwarding', line: 'X11Forwarding no' }\n        - { regexp: '^#?MaxAuthTries', line: 'MaxAuthTries 3' }\n        - { regexp: '^#?ClientAliveInterval', line: 'ClientAliveInterval 300' }\n        - { regexp: '^#?ClientAliveCountMax', line: 'ClientAliveCountMax 2' }\n      notify: restart ssh\n    \n    - name: Set up fail2ban\n      copy:\n        dest: /etc/fail2ban/jail.local\n        content: |\n          [DEFAULT]\n          bantime = 3600\n          findtime = 600\n          maxretry = 3\n          \n          [sshd]\n          enabled = true\n          port = ssh\n          logpath = /var/log/auth.log\n          maxretry = 3\n      notify: restart fail2ban\n    \n    - name: Configure kernel parameters\n      sysctl:\n        name: \"{{ item.name }}\"\n        value: \"{{ item.value }}\"\n        state: present\n        reload: yes\n      loop:\n        - { name: 'net.ipv4.conf.all.send_redirects', value: '0' }\n        - { name: 'net.ipv4.conf.default.send_redirects', value: '0' }\n        - { name: 'net.ipv4.conf.all.accept_redirects', value: '0' }\n        - { name: 'net.ipv4.conf.default.accept_redirects', value: '0' }\n        - { name: 'net.ipv4.ip_forward', value: '0' }\n        - { name: 'net.ipv4.conf.all.log_martians', value: '1' }\n    \n    - name: Remove unnecessary packages\n      apt:\n        name:\n          - telnet\n          - rsh-client\n          - rsh-redone-client\n        state: absent\n        purge: yes\n  \n  handlers:\n    - name: restart ssh\n      service:\n        name: ssh\n        state: restarted\n    \n    - name: restart fail2ban\n      service:\n        name: fail2ban\n        state: restarted\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"-step-4-cicd-integration",children:"\ud83d\udcca Step 4: CI/CD Integration"}),"\n",(0,s.jsx)(e.h3,{id:"github-actions-workflow",children:"GitHub Actions Workflow"}),"\n",(0,s.jsxs)(e.p,{children:["Create ",(0,s.jsx)(e.code,{children:".github/workflows/packer-build.yml"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-yaml",children:'name: Packer Image Build\n\non:\n  push:\n    branches: [ main ]\n    paths: \n      - \'packer/**\'\n      - \'scripts/**\'\n      - \'ansible/**\'\n  pull_request:\n    branches: [ main ]\n    paths:\n      - \'packer/**\'\n      - \'scripts/**\'\n      - \'ansible/**\'\n\nenv:\n  PACKER_VERSION: "1.9.4"\n\njobs:\n  validate:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      \n      - name: Setup Packer\n        uses: hashicorp/setup-packer@main\n        with:\n          version: ${{ env.PACKER_VERSION }}\n      \n      - name: Validate Packer templates\n        run: |\n          packer validate packer/aws-ubuntu.pkr.hcl\n          packer validate packer/multi-platform.pkr.hcl\n      \n      - name: Format check\n        run: |\n          packer fmt -check packer/\n\n  build-aws:\n    needs: validate\n    runs-on: ubuntu-latest\n    if: github.ref == \'refs/heads/main\'\n    \n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      \n      - name: Setup Packer\n        uses: hashicorp/setup-packer@main\n        with:\n          version: ${{ env.PACKER_VERSION }}\n      \n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          aws-region: us-west-2\n      \n      - name: Build AWS AMI\n        run: |\n          packer build \\\n            -var "ami_name=webapp-$(date +%Y%m%d%H%M%S)" \\\n            packer/aws-ubuntu.pkr.hcl\n      \n      - name: Get AMI ID\n        id: ami\n        run: |\n          AMI_ID=$(aws ec2 describe-images \\\n            --owners self \\\n            --query \'Images | sort_by(@, &CreationDate) | [-1].ImageId\' \\\n            --output text)\n          echo "ami_id=$AMI_ID" >> $GITHUB_OUTPUT\n      \n      - name: Update Terraform variables\n        run: |\n          echo "ami_id = \\"${{ steps.ami.outputs.ami_id }}\\"" > terraform/ami.auto.tfvars\n          git config --local user.email "action@github.com"\n          git config --local user.name "GitHub Action"\n          git add terraform/ami.auto.tfvars\n          git commit -m "Update AMI ID: ${{ steps.ami.outputs.ami_id }}" || exit 0\n          git push\n\n  build-multi-platform:\n    needs: validate\n    runs-on: ubuntu-latest\n    if: github.ref == \'refs/heads/main\'\n    strategy:\n      matrix:\n        platform: [aws, azure, gcp]\n    \n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      \n      - name: Setup Packer\n        uses: hashicorp/setup-packer@main\n        with:\n          version: ${{ env.PACKER_VERSION }}\n      \n      - name: Build ${{ matrix.platform }} image\n        env:\n          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}\n          ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}\n          ARM_SUBSCRIPTION_ID: ${{ secrets.ARM_SUBSCRIPTION_ID }}\n          ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}\n          GOOGLE_APPLICATION_CREDENTIALS_JSON: ${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}\n        run: |\n          if [ "${{ matrix.platform }}" = "gcp" ]; then\n            echo "$GOOGLE_APPLICATION_CREDENTIALS_JSON" > /tmp/gcp-key.json\n            export GOOGLE_APPLICATION_CREDENTIALS=/tmp/gcp-key.json\n          fi\n          \n          packer build \\\n            -only="${{ matrix.platform }}.*" \\\n            -var "version=${{ github.sha }}" \\\n            packer/multi-platform.pkr.hcl\n```---\n\n#\n# \ud83d\udd0d What You\'ll See\n\n### Packer Build Output\n```bash\n$ packer build aws-ubuntu.pkr.hcl\n\namazon-ebs.ubuntu: output will be in this color.\n\n==> amazon-ebs.ubuntu: Prevalidating any provided VPC information\n==> amazon-ebs.ubuntu: Prevalidating AMI Name: custom-ubuntu-20240115103000\n==> amazon-ebs.ubuntu: Creating temporary keypair: packer_63f8a123-4567-8901-2345-678901234567\n==> amazon-ebs.ubuntu: Creating temporary security group for this instance: packer_63f8a123\n==> amazon-ebs.ubuntu: Authorizing access to port 22 from [0.0.0.0/0] in the temporary security groups...\n==> amazon-ebs.ubuntu: Launching a source AWS instance...\n==> amazon-ebs.ubuntu: Adding tags to source instance\n    amazon-ebs.ubuntu: Adding tag: "Name": "Packer Builder"\n==> amazon-ebs.ubuntu: Waiting for instance (i-0123456789abcdef0) to become ready...\n==> amazon-ebs.ubuntu: Using SSH communicator to connect: 54.123.45.67\n==> amazon-ebs.ubuntu: Waiting for SSH to become available...\n==> amazon-ebs.ubuntu: Connected to SSH!\n==> amazon-ebs.ubuntu: Provisioning with shell script: scripts/install-docker.sh\n    amazon-ebs.ubuntu: Installing Docker...\n    amazon-ebs.ubuntu: Docker installation completed!\n==> amazon-ebs.ubuntu: Provisioning with Ansible...\n    amazon-ebs.ubuntu: PLAY [Security Hardening] ******************************************************\n    amazon-ebs.ubuntu: TASK [Update all packages] *****************************************************\n    amazon-ebs.ubuntu: ok: [default]\n    amazon-ebs.ubuntu: PLAY RECAP *********************************************************************\n    amazon-ebs.ubuntu: default                    : ok=15   changed=8    unreachable=0    failed=0\n==> amazon-ebs.ubuntu: Stopping the source instance...\n==> amazon-ebs.ubuntu: Waiting for the instance to stop...\n==> amazon-ebs.ubuntu: Creating AMI custom-ubuntu-20240115103000 from instance i-0123456789abcdef0\n==> amazon-ebs.ubuntu: Waiting for AMI to become ready...\n==> amazon-ebs.ubuntu: Terminating the source AWS instance...\n==> amazon-ebs.ubuntu: Cleaning up any extra volumes...\n==> amazon-ebs.ubuntu: No volumes to clean up, skipping\n==> amazon-ebs.ubuntu: Deleting temporary security group...\n==> amazon-ebs.ubuntu: Deleting temporary keypair...\nBuild \'amazon-ebs.ubuntu\' finished after 8 minutes 34 seconds.\n\n==> Wait completed after 8 minutes 34 seconds\n\n==> Builds finished. The artifacts of successful builds are:\n--\x3e amazon-ebs.ubuntu: AMIs were created:\nus-west-2: ami-0123456789abcdef0\n'})}),"\n",(0,s.jsx)(e.h3,{id:"multi-platform-build-results",children:"Multi-Platform Build Results"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"Build Summary:\n\u2705 AWS AMI: ami-0123456789abcdef0 (us-west-2)\n\u2705 Azure Image: webapp-20240115103000 (East US)\n\u2705 GCP Image: webapp-20240115103000 (us-central1)\n\nTotal build time: 12m 45s\nImages created: 3\nPlatforms: AWS, Azure, GCP\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"pros--cons",children:"Pros & Cons"}),"\n",(0,s.jsx)(e.h3,{id:"-pros",children:"\u2705 Pros"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Multi-Platform"}),": Single configuration for multiple platforms"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Immutable Infrastructure"}),": Consistent, reproducible images"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Automation"}),": Integrates well with CI/CD pipelines"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Provisioner Support"}),": Works with Ansible, Chef, Puppet, Shell"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Parallel Builds"}),": Build multiple images simultaneously"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"-cons",children:"\u274c Cons"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Build Time"}),": Image creation can be time-consuming"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Storage Costs"}),": Multiple images across platforms increase costs"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Complexity"}),": Advanced configurations can become complex"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Debugging"}),": Troubleshooting failed builds can be challenging"]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,s.jsxs)(e.p,{children:["HashiCorp Packer is the ",(0,s.jsx)(e.strong,{children:"standard tool"})," for ",(0,s.jsx)(e.strong,{children:"automated machine image creation"}),". Choose Packer when you need:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Immutable infrastructure"})," with consistent machine images"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Multi-cloud deployments"})," with identical configurations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Automated image pipelines"})," integrated with CI/CD"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Security hardening"})," baked into base images"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"The combination of multi-platform support, automation capabilities, and immutable infrastructure principles makes Packer essential for modern infrastructure management."}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"What You've Achieved:"}),"\n\u2705 Set up automated machine image creation across multiple platforms",(0,s.jsx)(e.br,{}),"\n","\u2705 Implemented security hardening and monitoring in base images",(0,s.jsx)(e.br,{}),"\n","\u2705 Created CI/CD integration for automated image builds",(0,s.jsx)(e.br,{}),"\n","\u2705 Built consistent, reproducible infrastructure images",(0,s.jsx)(e.br,{}),"\n","\u2705 Established image versioning and artifact management"]})]})}function d(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(u,{...n})}):u(n)}},8453:(n,e,a)=>{a.d(e,{R:()=>i,x:()=>o});var t=a(6540);const s={},r=t.createContext(s);function i(n){const e=t.useContext(r);return t.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:i(n.components),t.createElement(r.Provider,{value:e},n.children)}}}]);