"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[2845],{8075:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"Observability/splunk","title":"Splunk","description":"Splunk is a comprehensive platform for searching, monitoring, and analyzing machine-generated data in real-time for operational intelligence and security.","source":"@site/docs/Observability/splunk.md","sourceDirName":"Observability","slug":"/Observability/Splunk","permalink":"/docs/Observability/Splunk","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Observability/splunk.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"title":"Splunk","description":"Splunk is a comprehensive platform for searching, monitoring, and analyzing machine-generated data in real-time for operational intelligence and security.","slug":"/Observability/Splunk","keywords":["Splunk","log analysis","machine data","SIEM","operational intelligence","security monitoring","data analytics","enterprise monitoring"]},"sidebar":"tutorialSidebar","previous":{"title":"Jaeger","permalink":"/docs/Observability/Jaeger"},"next":{"title":"OpenTelemetry","permalink":"/docs/Observability/OpenTelemetry"}}');var r=s(4848),i=s(8453);const a={sidebar_position:6,title:"Splunk",description:"Splunk is a comprehensive platform for searching, monitoring, and analyzing machine-generated data in real-time for operational intelligence and security.",slug:"/Observability/Splunk",keywords:["Splunk","log analysis","machine data","SIEM","operational intelligence","security monitoring","data analytics","enterprise monitoring"]},o="\ud83d\udd0d Enterprise Data Analytics with Splunk",l={},c=[{value:"Key Features",id:"key-features",level:2},{value:"Use Cases",id:"use-cases",level:2},{value:"\ud83e\uddf0 Prerequisites",id:"-prerequisites",level:2},{value:"\ud83d\udd27 Step 1: Splunk Enterprise Setup",id:"-step-1-splunk-enterprise-setup",level:2},{value:"Docker Compose Configuration",id:"docker-compose-configuration",level:3},{value:"\ud83c\udfd7\ufe0f Step 2: Data Ingestion Configuration",id:"\ufe0f-step-2-data-ingestion-configuration",level:2},{value:"HTTP Event Collector Setup",id:"http-event-collector-setup",level:3},{value:"Sample Log Generator",id:"sample-log-generator",level:3},{value:"\u25b6\ufe0f Step 3: Advanced Search and Analytics",id:"\ufe0f-step-3-advanced-search-and-analytics",level:2},{value:"Splunk Search Processing Language (SPL) Examples",id:"splunk-search-processing-language-spl-examples",level:3},{value:"Custom Dashboard Configuration",id:"custom-dashboard-configuration",level:3},{value:"\ud83d\udcca Step 4: Advanced Analytics and Machine Learning",id:"-step-4-advanced-analytics-and-machine-learning",level:2},{value:"Anomaly Detection with MLTK",id:"anomaly-detection-with-mltk",level:3},{value:"\ud83d\udd0d What You&#39;ll See",id:"-what-youll-see",level:2},{value:"Splunk Web Interface",id:"splunk-web-interface",level:3},{value:"Search Results Example",id:"search-results-example",level:3},{value:"Dashboard Metrics",id:"dashboard-metrics",level:3},{value:"ML Analytics Report",id:"ml-analytics-report",level:3},{value:"Pros &amp; Cons",id:"pros--cons",level:2},{value:"\u2705 Pros",id:"-pros",level:3},{value:"\u274c Cons",id:"-cons",level:3},{value:"Conclusion",id:"conclusion",level:2}];function d(e){const n={br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"-enterprise-data-analytics-with-splunk",children:"\ud83d\udd0d Enterprise Data Analytics with Splunk"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Splunk"})," is a ",(0,r.jsx)(n.strong,{children:"comprehensive platform"})," for ",(0,r.jsx)(n.strong,{children:"searching"}),", ",(0,r.jsx)(n.strong,{children:"monitoring"}),", and ",(0,r.jsx)(n.strong,{children:"analyzing"})," machine-generated data in real-time. Perfect for ",(0,r.jsx)(n.strong,{children:"operational intelligence"}),", ",(0,r.jsx)(n.strong,{children:"security monitoring"}),", ",(0,r.jsx)(n.strong,{children:"compliance"}),", and ",(0,r.jsx)(n.strong,{children:"business analytics"})," with ",(0,r.jsx)(n.strong,{children:"powerful search capabilities"})," and ",(0,r.jsx)(n.strong,{children:"advanced visualizations"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"key-features",children:"Key Features"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Universal Data Ingestion"}),": Collect data from any source, format, or volume"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Real-time Search"}),": Powerful search processing language (SPL)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Machine Learning"}),": Built-in ML capabilities for anomaly detection"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Security Analytics"}),": SIEM capabilities with threat detection"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Scalable Architecture"}),": Distributed deployment for enterprise scale"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"IT Operations"}),": Infrastructure monitoring and troubleshooting"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Security Operations"}),": Threat detection and incident response"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Business Analytics"}),": KPI monitoring and business intelligence"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Compliance"}),": Audit trails and regulatory reporting"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-prerequisites",children:"\ud83e\uddf0 Prerequisites"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Docker & Docker Compose"})," for containerized setup"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"8GB+ RAM"})," recommended for Splunk Enterprise"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"SSD storage"})," for better indexing performance"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Network access"})," for data collection from multiple sources"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Splunk license"})," for production use (free for development)"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-step-1-splunk-enterprise-setup",children:"\ud83d\udd27 Step 1: Splunk Enterprise Setup"}),"\n",(0,r.jsx)(n.h3,{id:"docker-compose-configuration",children:"Docker Compose Configuration"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'version: \'3.8\'\n\nservices:\n  # Splunk Enterprise\n  splunk-enterprise:\n    image: splunk/splunk:9.1.2\n    container_name: splunk-enterprise\n    restart: unless-stopped\n    ports:\n      - "8000:8000"   # Web UI\n      - "8088:8088"   # HTTP Event Collector\n      - "8089:8089"   # Management port\n      - "9997:9997"   # Indexer port\n      - "514:514/udp" # Syslog\n    environment:\n      - SPLUNK_START_ARGS=--accept-license\n      - SPLUNK_PASSWORD=changeme123\n      - SPLUNK_HEC_TOKEN=abcd1234-ef56-7890-abcd-1234567890ab\n      - SPLUNK_APPS_URL=https://splunkbase.splunk.com/app/742/release/8.0.0/download\n    volumes:\n      - splunk-etc:/opt/splunk/etc\n      - splunk-var:/opt/splunk/var\n      - ./splunk-apps:/opt/splunk/etc/apps\n      - ./data:/data\n    healthcheck:\n      test: ["CMD", "curl", "-f", "http://localhost:8000/en-US/account/login"]\n      interval: 30s\n      timeout: 10s\n      retries: 5\n\n  # Universal Forwarder for log collection\n  splunk-forwarder:\n    image: splunk/universalforwarder:9.1.2\n    container_name: splunk-forwarder\n    restart: unless-stopped\n    environment:\n      - SPLUNK_START_ARGS=--accept-license\n      - SPLUNK_PASSWORD=changeme123\n      - SPLUNK_FORWARD_SERVER=splunk-enterprise:9997\n    volumes:\n      - ./forwarder-config:/opt/splunkforwarder/etc/apps/search/local\n      - /var/log:/host/var/log:ro\n      - /var/lib/docker/containers:/host/var/lib/docker/containers:ro\n    depends_on:\n      splunk-enterprise:\n        condition: service_healthy\n\n  # Sample application generating logs\n  log-generator:\n    image: python:3.11-slim\n    container_name: log-generator\n    restart: unless-stopped\n    volumes:\n      - ./log-generator:/app\n      - ./data/logs:/var/log/app\n    working_dir: /app\n    command: python generate_logs.py\n    depends_on:\n      - splunk-enterprise\n\n  # Nginx for web server logs\n  nginx-sample:\n    image: nginx:alpine\n    container_name: nginx-sample\n    restart: unless-stopped\n    ports:\n      - "8080:80"\n    volumes:\n      - ./nginx-config:/etc/nginx/conf.d\n      - ./data/nginx-logs:/var/log/nginx\n    depends_on:\n      - splunk-enterprise\n\nvolumes:\n  splunk-etc:\n  splunk-var:\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"\ufe0f-step-2-data-ingestion-configuration",children:"\ud83c\udfd7\ufe0f Step 2: Data Ingestion Configuration"}),"\n",(0,r.jsx)(n.h3,{id:"http-event-collector-setup",children:"HTTP Event Collector Setup"}),"\n",(0,r.jsxs)(n.p,{children:["Create ",(0,r.jsx)(n.code,{children:"splunk-config/inputs.conf"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-ini",children:"[http]\ndisabled = 0\n\n[http://hec_token]\ndisabled = 0\ntoken = abcd1234-ef56-7890-abcd-1234567890ab\nindexes = main,security,application\nsourcetypes = _json,access_log,error_log\n\n[monitor:///var/log/app/*.log]\ndisabled = false\nindex = application\nsourcetype = application_log\nhost_segment = 3\n\n[monitor:///var/log/nginx/access.log]\ndisabled = false\nindex = web\nsourcetype = access_combined\nhost_segment = 2\n\n[monitor:///var/log/nginx/error.log]\ndisabled = false\nindex = web\nsourcetype = nginx_error\nhost_segment = 2\n\n[udp://514]\ndisabled = false\nindex = network\nsourcetype = syslog\n"})}),"\n",(0,r.jsx)(n.h3,{id:"sample-log-generator",children:"Sample Log Generator"}),"\n",(0,r.jsxs)(n.p,{children:["Create ",(0,r.jsx)(n.code,{children:"log-generator/generate_logs.py"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport json\nimport time\nimport random\nimport logging\nfrom datetime import datetime\nimport requests\nimport threading\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('/var/log/app/application.log'),\n        logging.StreamHandler()\n    ]\n)\n\nlogger = logging.getLogger(__name__)\n\nclass SplunkHECLogger:\n    \"\"\"Send logs to Splunk HTTP Event Collector\"\"\"\n    \n    def __init__(self, hec_url, hec_token):\n        self.hec_url = hec_url\n        self.hec_token = hec_token\n        self.session = requests.Session()\n        self.session.headers.update({\n            'Authorization': f'Splunk {hec_token}',\n            'Content-Type': 'application/json'\n        })\n    \n    def send_event(self, event_data, source=None, sourcetype=None, index=None):\n        \"\"\"Send event to Splunk HEC\"\"\"\n        event = {\n            'time': time.time(),\n            'event': event_data\n        }\n        \n        if source:\n            event['source'] = source\n        if sourcetype:\n            event['sourcetype'] = sourcetype\n        if index:\n            event['index'] = index\n        \n        try:\n            response = self.session.post(self.hec_url, json=event, timeout=5)\n            if response.status_code != 200:\n                logger.error(f\"HEC error: {response.status_code} - {response.text}\")\n        except Exception as e:\n            logger.error(f\"Failed to send to HEC: {e}\")\n\ndef generate_application_logs():\n    \"\"\"Generate application logs\"\"\"\n    users = ['alice', 'bob', 'charlie', 'diana', 'eve']\n    actions = ['login', 'logout', 'view_page', 'purchase', 'search', 'upload', 'download']\n    statuses = ['success', 'failure', 'timeout', 'error']\n    \n    while True:\n        user = random.choice(users)\n        action = random.choice(actions)\n        status = random.choice(statuses)\n        duration = random.uniform(0.1, 5.0)\n        \n        log_entry = {\n            'timestamp': datetime.utcnow().isoformat(),\n            'user': user,\n            'action': action,\n            'status': status,\n            'duration': round(duration, 3),\n            'ip_address': f'192.168.1.{random.randint(1, 254)}',\n            'user_agent': 'Mozilla/5.0 (compatible; AppClient/1.0)',\n            'session_id': f'sess_{random.randint(1000, 9999)}'\n        }\n        \n        # Log to file\n        logger.info(json.dumps(log_entry))\n        \n        # Send to Splunk HEC\n        hec_logger.send_event(\n            log_entry,\n            source='application',\n            sourcetype='json_application',\n            index='application'\n        )\n        \n        time.sleep(random.uniform(0.5, 2.0))\n\ndef generate_security_events():\n    \"\"\"Generate security-related events\"\"\"\n    event_types = ['failed_login', 'suspicious_activity', 'privilege_escalation', 'data_access']\n    severity_levels = ['low', 'medium', 'high', 'critical']\n    \n    while True:\n        event_type = random.choice(event_types)\n        severity = random.choice(severity_levels)\n        \n        security_event = {\n            'timestamp': datetime.utcnow().isoformat(),\n            'event_type': event_type,\n            'severity': severity,\n            'source_ip': f'{random.randint(1, 255)}.{random.randint(1, 255)}.{random.randint(1, 255)}.{random.randint(1, 255)}',\n            'destination_ip': f'192.168.1.{random.randint(1, 254)}',\n            'user': random.choice(['admin', 'user1', 'service_account', 'unknown']),\n            'description': f'Security event: {event_type} detected',\n            'risk_score': random.randint(1, 100)\n        }\n        \n        # Log to file\n        security_logger = logging.getLogger('security')\n        security_logger.info(json.dumps(security_event))\n        \n        # Send to Splunk HEC\n        hec_logger.send_event(\n            security_event,\n            source='security_system',\n            sourcetype='json_security',\n            index='security'\n        )\n        \n        time.sleep(random.uniform(5.0, 15.0))\n\ndef generate_performance_metrics():\n    \"\"\"Generate performance metrics\"\"\"\n    metrics = ['cpu_usage', 'memory_usage', 'disk_usage', 'network_io']\n    \n    while True:\n        for metric in metrics:\n            value = random.uniform(10, 90) if metric.endswith('_usage') else random.uniform(100, 1000)\n            \n            metric_event = {\n                'timestamp': datetime.utcnow().isoformat(),\n                'metric_name': metric,\n                'value': round(value, 2),\n                'host': f'server-{random.randint(1, 5)}',\n                'environment': 'production',\n                'datacenter': random.choice(['us-east-1', 'us-west-2', 'eu-west-1'])\n            }\n            \n            # Send to Splunk HEC\n            hec_logger.send_event(\n                metric_event,\n                source='metrics_collector',\n                sourcetype='json_metrics',\n                index='metrics'\n            )\n        \n        time.sleep(30)\n\nif __name__ == \"__main__\":\n    # Initialize HEC logger\n    hec_logger = SplunkHECLogger(\n        hec_url='http://splunk-enterprise:8088/services/collector',\n        hec_token='abcd1234-ef56-7890-abcd-1234567890ab'\n    )\n    \n    # Start log generation threads\n    threads = [\n        threading.Thread(target=generate_application_logs, daemon=True),\n        threading.Thread(target=generate_security_events, daemon=True),\n        threading.Thread(target=generate_performance_metrics, daemon=True)\n    ]\n    \n    for thread in threads:\n        thread.start()\n    \n    logger.info(\"Log generation started\")\n    \n    # Keep main thread alive\n    try:\n        while True:\n            time.sleep(60)\n            logger.info(\"Log generator is running...\")\n    except KeyboardInterrupt:\n        logger.info(\"Shutting down log generator\")\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"\ufe0f-step-3-advanced-search-and-analytics",children:"\u25b6\ufe0f Step 3: Advanced Search and Analytics"}),"\n",(0,r.jsx)(n.h3,{id:"splunk-search-processing-language-spl-examples",children:"Splunk Search Processing Language (SPL) Examples"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-spl",children:'# Basic search for application logs\nindex=application sourcetype=json_application\n| stats count by user, action\n| sort -count\n\n# Security event analysis\nindex=security severity=high OR severity=critical\n| eval risk_category=case(\n    risk_score >= 80, "Critical",\n    risk_score >= 60, "High", \n    risk_score >= 40, "Medium",\n    1=1, "Low"\n)\n| stats count by event_type, risk_category\n| sort -count\n\n# Performance monitoring with time series\nindex=metrics metric_name=cpu_usage\n| timechart span=5m avg(value) by host\n| where avg(value) > 80\n\n# Failed login attempts analysis\nindex=application action=login status=failure\n| stats count as failed_attempts by user, ip_address\n| where failed_attempts > 5\n| sort -failed_attempts\n\n# Web server log analysis\nindex=web sourcetype=access_combined\n| rex field=_raw "(?<client_ip>\\d+\\.\\d+\\.\\d+\\.\\d+).*\\"(?<method>\\w+)\\s+(?<uri>\\S+)\\s+HTTP.*\\"\\s+(?<status>\\d+)\\s+(?<bytes>\\d+)"\n| stats count as requests, avg(bytes) as avg_bytes by status, method\n| eval avg_bytes=round(avg_bytes,2)\n| sort -requests\n\n# Anomaly detection using machine learning\nindex=metrics metric_name=cpu_usage\n| fit DensityFunction value into cpu_anomaly_model\n| apply cpu_anomaly_model\n| where IsOutlier > 0\n| table _time, host, value, IsOutlier\n\n# Correlation search across multiple indexes\nindex=application action=purchase\n| join session_id [\n    search index=web sourcetype=access_combined\n    | rex field=_raw "session_id=(?<session_id>\\w+)"\n    | stats count as page_views by session_id\n]\n| stats avg(page_views) as avg_pages_before_purchase\n\n# Real-time alerting query\nindex=security event_type=failed_login\n| stats count as failed_logins by source_ip\n| where failed_logins > 10\n| eval alert_message="Potential brute force attack from " + source_ip\n| table _time, source_ip, failed_logins, alert_message\n'})}),"\n",(0,r.jsx)(n.h3,{id:"custom-dashboard-configuration",children:"Custom Dashboard Configuration"}),"\n",(0,r.jsxs)(n.p,{children:["Create ",(0,r.jsx)(n.code,{children:"splunk-apps/custom_dashboard/default/data/ui/views/security_overview.xml"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-xml",children:'<form version="1.1">\n  <label>Security Overview Dashboard</label>\n  <description>Real-time security monitoring and threat detection</description>\n  \n  <fieldset submitButton="true" autoRun="true">\n    <input type="time" token="time_picker">\n      <label>Time Range</label>\n      <default>\n        <earliest>-24h@h</earliest>\n        <latest>now</latest>\n      </default>\n    </input>\n    \n    <input type="dropdown" token="severity_filter">\n      <label>Severity Level</label>\n      <choice value="*">All</choice>\n      <choice value="critical">Critical</choice>\n      <choice value="high">High</choice>\n      <choice value="medium">Medium</choice>\n      <choice value="low">Low</choice>\n      <default>*</default>\n    </input>\n  </fieldset>\n  \n  <row>\n    <panel>\n      <single>\n        <title>Total Security Events</title>\n        <search>\n          <query>\n            index=security severity=$severity_filter$\n            | stats count\n          </query>\n          <earliest>$time_picker.earliest$</earliest>\n          <latest>$time_picker.latest$</latest>\n        </search>\n        <option name="drilldown">none</option>\n        <option name="colorBy">value</option>\n        <option name="colorMode">block</option>\n        <option name="rangeColors">["0x65A637","0xF7BC38","0xF58F39","0xD93F3C"]</option>\n        <option name="rangeValues">[0,100,500,1000]</option>\n      </single>\n    </panel>\n    \n    <panel>\n      <single>\n        <title>Critical Events</title>\n        <search>\n          <query>\n            index=security severity=critical\n            | stats count\n          </query>\n          <earliest>$time_picker.earliest$</earliest>\n          <latest>$time_picker.latest$</latest>\n        </search>\n        <option name="drilldown">none</option>\n        <option name="colorBy">value</option>\n        <option name="colorMode">block</option>\n        <option name="rangeColors">["0x65A637","0xF58F39","0xD93F3C"]</option>\n        <option name="rangeValues">[0,5,20]</option>\n      </single>\n    </panel>\n    \n    <panel>\n      <single>\n        <title>Unique Source IPs</title>\n        <search>\n          <query>\n            index=security severity=$severity_filter$\n            | stats dc(source_ip) as unique_ips\n          </query>\n          <earliest>$time_picker.earliest$</earliest>\n          <latest>$time_picker.latest$</latest>\n        </search>\n        <option name="drilldown">none</option>\n      </single>\n    </panel>\n  </row>\n  \n  <row>\n    <panel>\n      <chart>\n        <title>Security Events Over Time</title>\n        <search>\n          <query>\n            index=security severity=$severity_filter$\n            | timechart span=1h count by severity\n          </query>\n          <earliest>$time_picker.earliest$</earliest>\n          <latest>$time_picker.latest$</latest>\n        </search>\n        <option name="charting.chart">column</option>\n        <option name="charting.chart.stackMode">stacked</option>\n        <option name="charting.legend.placement">bottom</option>\n      </chart>\n    </panel>\n    \n    <panel>\n      <chart>\n        <title>Top Event Types</title>\n        <search>\n          <query>\n            index=security severity=$severity_filter$\n            | stats count by event_type\n            | sort -count\n            | head 10\n          </query>\n          <earliest>$time_picker.earliest$</earliest>\n          <latest>$time_picker.latest$</latest>\n        </search>\n        <option name="charting.chart">pie</option>\n        <option name="charting.legend.placement">right</option>\n      </chart>\n    </panel>\n  </row>\n  \n  <row>\n    <panel>\n      <table>\n        <title>High-Risk Events</title>\n        <search>\n          <query>\n            index=security severity=$severity_filter$ risk_score>=70\n            | eval risk_level=case(\n                risk_score>=90, "Critical",\n                risk_score>=80, "High",\n                risk_score>=70, "Medium",\n                1=1, "Low"\n              )\n            | table _time, event_type, source_ip, user, risk_score, risk_level, description\n            | sort -risk_score\n            | head 20\n          </query>\n          <earliest>$time_picker.earliest$</earliest>\n          <latest>$time_picker.latest$</latest>\n        </search>\n        <option name="drilldown">cell</option>\n        <option name="dataOverlayMode">none</option>\n        <option name="rowNumbers">true</option>\n        <option name="wrap">false</option>\n      </table>\n    </panel>\n  </row>\n</form>\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-step-4-advanced-analytics-and-machine-learning",children:"\ud83d\udcca Step 4: Advanced Analytics and Machine Learning"}),"\n",(0,r.jsx)(n.h3,{id:"anomaly-detection-with-mltk",children:"Anomaly Detection with MLTK"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# splunk_ml_analytics.py\nimport splunklib.client as client\nimport splunklib.results as results\nimport pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler\nimport json\nimport time\n\nclass SplunkMLAnalytics:\n    \"\"\"Advanced analytics for Splunk data\"\"\"\n    \n    def __init__(self, host='localhost', port=8089, username='admin', password='changeme123'):\n        self.service = client.connect(\n            host=host,\n            port=port,\n            username=username,\n            password=password\n        )\n        \n    def run_search(self, search_query, **kwargs):\n        \"\"\"Execute Splunk search and return results\"\"\"\n        job = self.service.jobs.create(search_query, **kwargs)\n        \n        # Wait for job completion\n        while not job.is_done():\n            time.sleep(0.5)\n        \n        # Get results\n        results_reader = results.ResultsReader(job.results())\n        data = []\n        for result in results_reader:\n            if isinstance(result, dict):\n                data.append(result)\n        \n        return pd.DataFrame(data)\n    \n    def detect_cpu_anomalies(self, lookback_hours=24):\n        \"\"\"Detect CPU usage anomalies using Isolation Forest\"\"\"\n        search_query = f\"\"\"\n        search index=metrics metric_name=cpu_usage earliest=-{lookback_hours}h\n        | eval value=tonumber(value)\n        | stats avg(value) as avg_cpu, max(value) as max_cpu, min(value) as min_cpu by host, _time\n        | sort _time\n        \"\"\"\n        \n        df = self.run_search(search_query)\n        \n        if df.empty:\n            return pd.DataFrame()\n        \n        # Prepare features\n        features = ['avg_cpu', 'max_cpu', 'min_cpu']\n        X = df[features].astype(float)\n        \n        # Standardize features\n        scaler = StandardScaler()\n        X_scaled = scaler.fit_transform(X)\n        \n        # Detect anomalies\n        iso_forest = IsolationForest(contamination=0.1, random_state=42)\n        anomalies = iso_forest.fit_predict(X_scaled)\n        \n        # Add anomaly results to dataframe\n        df['anomaly'] = anomalies\n        df['anomaly_score'] = iso_forest.score_samples(X_scaled)\n        \n        # Return only anomalies\n        anomalies_df = df[df['anomaly'] == -1].copy()\n        anomalies_df = anomalies_df.sort_values('anomaly_score')\n        \n        return anomalies_df\n    \n    def analyze_user_behavior(self, lookback_hours=24):\n        \"\"\"Analyze user behavior patterns\"\"\"\n        search_query = f\"\"\"\n        search index=application earliest=-{lookback_hours}h\n        | stats count as total_actions, \n                dc(action) as unique_actions,\n                dc(ip_address) as unique_ips,\n                avg(duration) as avg_duration\n                by user\n        | eval behavior_score = (total_actions * unique_actions) / (unique_ips + 1)\n        | sort -behavior_score\n        \"\"\"\n        \n        df = self.run_search(search_query)\n        \n        if df.empty:\n            return pd.DataFrame()\n        \n        # Convert numeric columns\n        numeric_cols = ['total_actions', 'unique_actions', 'unique_ips', 'avg_duration', 'behavior_score']\n        for col in numeric_cols:\n            if col in df.columns:\n                df[col] = pd.to_numeric(df[col], errors='coerce')\n        \n        # Identify suspicious behavior\n        df['suspicious'] = (\n            (df['unique_ips'] > df['unique_ips'].quantile(0.95)) |\n            (df['behavior_score'] > df['behavior_score'].quantile(0.95))\n        )\n        \n        return df\n    \n    def security_threat_analysis(self, lookback_hours=24):\n        \"\"\"Comprehensive security threat analysis\"\"\"\n        search_query = f\"\"\"\n        search index=security earliest=-{lookback_hours}h\n        | eval risk_category = case(\n            risk_score >= 80, \"Critical\",\n            risk_score >= 60, \"High\",\n            risk_score >= 40, \"Medium\",\n            1=1, \"Low\"\n          )\n        | stats count as event_count,\n                avg(risk_score) as avg_risk,\n                max(risk_score) as max_risk,\n                dc(event_type) as unique_event_types\n                by source_ip, risk_category\n        | sort -avg_risk\n        \"\"\"\n        \n        df = self.run_search(search_query)\n        \n        if df.empty:\n            return pd.DataFrame()\n        \n        # Convert numeric columns\n        numeric_cols = ['event_count', 'avg_risk', 'max_risk', 'unique_event_types']\n        for col in numeric_cols:\n            if col in df.columns:\n                df[col] = pd.to_numeric(df[col], errors='coerce')\n        \n        # Calculate threat score\n        df['threat_score'] = (\n            df['event_count'] * 0.3 +\n            df['avg_risk'] * 0.4 +\n            df['unique_event_types'] * 0.3\n        )\n        \n        # Identify high-threat IPs\n        df['high_threat'] = df['threat_score'] > df['threat_score'].quantile(0.9)\n        \n        return df.sort_values('threat_score', ascending=False)\n    \n    def generate_ml_report(self):\n        \"\"\"Generate comprehensive ML analytics report\"\"\"\n        report = {\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'cpu_anomalies': [],\n            'user_behavior_analysis': [],\n            'security_threats': []\n        }\n        \n        # CPU anomaly detection\n        cpu_anomalies = self.detect_cpu_anomalies()\n        if not cpu_anomalies.empty:\n            report['cpu_anomalies'] = cpu_anomalies.to_dict('records')\n        \n        # User behavior analysis\n        user_behavior = self.analyze_user_behavior()\n        if not user_behavior.empty:\n            suspicious_users = user_behavior[user_behavior['suspicious'] == True]\n            report['user_behavior_analysis'] = suspicious_users.to_dict('records')\n        \n        # Security threat analysis\n        security_threats = self.security_threat_analysis()\n        if not security_threats.empty:\n            high_threats = security_threats[security_threats['high_threat'] == True]\n            report['security_threats'] = high_threats.to_dict('records')\n        \n        return report\n\nif __name__ == \"__main__\":\n    # Initialize analytics\n    analytics = SplunkMLAnalytics()\n    \n    # Generate ML report\n    report = analytics.generate_ml_report()\n    \n    # Print report\n    print(\"Splunk ML Analytics Report\")\n    print(\"=\" * 50)\n    print(json.dumps(report, indent=2, default=str))\n    \n    # Save report\n    with open(f'/data/ml_report_{int(time.time())}.json', 'w') as f:\n        json.dump(report, f, indent=2, default=str)\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-what-youll-see",children:"\ud83d\udd0d What You'll See"}),"\n",(0,r.jsx)(n.h3,{id:"splunk-web-interface",children:"Splunk Web Interface"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Search & Reporting"}),": Powerful SPL search interface"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Dashboards"}),": Real-time visualizations and KPIs"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Alerts"}),": Automated alerting based on search criteria"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Machine Learning"}),": Built-in ML capabilities for anomaly detection"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"search-results-example",children:"Search Results Example"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"index=application action=login status=failure\n| stats count as failed_attempts by user, ip_address\n| where failed_attempts > 5\n\nResults:\nuser        ip_address      failed_attempts\nalice       192.168.1.100   12\nbob         10.0.1.50       8\ncharlie     172.16.0.25     7\n"})}),"\n",(0,r.jsx)(n.h3,{id:"dashboard-metrics",children:"Dashboard Metrics"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Security Events"}),": 1,247 events (last 24h)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Critical Alerts"}),": 23 critical events"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Top Threat IPs"}),": 5 high-risk IP addresses"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Anomalies Detected"}),": 12 CPU usage anomalies"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"ml-analytics-report",children:"ML Analytics Report"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "timestamp": "2024-01-15T10:30:00",\n  "cpu_anomalies": [\n    {\n      "host": "server-3",\n      "avg_cpu": 95.2,\n      "anomaly_score": -0.85,\n      "_time": "2024-01-15T09:45:00"\n    }\n  ],\n  "security_threats": [\n    {\n      "source_ip": "203.0.113.45",\n      "threat_score": 87.3,\n      "event_count": 156,\n      "avg_risk": 78.5\n    }\n  ]\n}\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"pros--cons",children:"Pros & Cons"}),"\n",(0,r.jsx)(n.h3,{id:"-pros",children:"\u2705 Pros"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Universal Data Ingestion"}),": Handle any data format or source"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Powerful Search"}),": Advanced SPL for complex data analysis"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Real-time Processing"}),": Process and analyze data as it arrives"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Enterprise Scale"}),": Handles petabytes of data with distributed architecture"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Security Focus"}),": Built-in SIEM capabilities and threat detection"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"-cons",children:"\u274c Cons"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Cost"}),": Expensive licensing model based on data volume"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Learning Curve"}),": SPL requires training and expertise"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Resource Intensive"}),": High CPU and storage requirements"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Vendor Lock-in"}),": Proprietary platform and search language"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,r.jsxs)(n.p,{children:["Splunk is the ",(0,r.jsx)(n.strong,{children:"enterprise standard"})," for ",(0,r.jsx)(n.strong,{children:"comprehensive data analytics"})," and ",(0,r.jsx)(n.strong,{children:"security monitoring"}),". Choose Splunk when you need:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Universal data ingestion"})," from any source or format"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Advanced search capabilities"})," with powerful SPL"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Real-time security monitoring"})," and threat detection"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Enterprise-scale"})," data processing and analytics"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"The combination of powerful search, real-time processing, and security focus makes Splunk ideal for large enterprises with complex data analytics and security requirements."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"What You've Achieved:"}),"\n\u2705 Set up enterprise Splunk environment with data ingestion",(0,r.jsx)(n.br,{}),"\n","\u2705 Created comprehensive dashboards and visualizations",(0,r.jsx)(n.br,{}),"\n","\u2705 Implemented advanced search queries and analytics",(0,r.jsx)(n.br,{}),"\n","\u2705 Built machine learning models for anomaly detection",(0,r.jsx)(n.br,{}),"\n","\u2705 Established security monitoring and threat detection",(0,r.jsx)(n.br,{}),"\n","\u2705 Developed automated reporting and alerting systems"]})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>o});var t=s(6540);const r={},i=t.createContext(r);function a(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);